{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from overcooked_ai_py.utils import save_pickle, load_pickle\n",
    "\n",
    "from human_aware_rl.experiments.planning_experiments import P_BC_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bc_model_paths = load_pickle(\"data/bc_runs/best_bc_model_paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counters = {'simple': [(1,0), (3,0), (0,2), (4,2), (2,3)],'random0': [(1, 0), (2, 1), (2, 2), (4, 2), (2, 3), (4, 3), (1, 4)] }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-based planner + counters - random0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delivery horizon for layout random0: 1\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From c:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\stable-baselines\\stable_baselines\\common\\policies.py:436: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From c:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Loaded MediumLevelPlanner from c:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\data\\planners\\random0_am.pkl\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "Loaded MediumLevelPlanner from c:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\data\\planners\\random0_am.pkl\n",
      "Drop locations:  [(1, 0), (2, 1), (2, 2), (4, 2), (2, 3), (4, 3), (1, 4)]\n",
      "Pickup locations:  [(1, 0), (2, 1), (2, 2), (4, 2), (2, 3), (4, 3), (1, 4)]\n",
      "Valid counters:  [(1, 0), (2, 1), (2, 2), (4, 2), (2, 3), (4, 3), (1, 4)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "Found goal after: \t103.99 seconds,   \t6896 state expanded (0.16 unique) \t ~66.31 expansions/s\n",
      "Timestep: 1\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t142.16 seconds,   \t6895 state expanded (0.16 unique) \t ~48.50 expansions/s\n",
      "Timestep: 2\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t101.01 seconds,   \t6894 state expanded (0.16 unique) \t ~68.25 expansions/s\n",
      "Timestep: 3\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t116.05 seconds,   \t6893 state expanded (0.16 unique) \t ~59.39 expansions/s\n",
      "Timestep: 4\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t114.86 seconds,   \t6892 state expanded (0.16 unique) \t ~60.00 expansions/s\n",
      "Timestep: 5\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t127.65 seconds,   \t6891 state expanded (0.16 unique) \t ~53.98 expansions/s\n",
      "Timestep: 6\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t143.11 seconds,   \t6890 state expanded (0.16 unique) \t ~48.15 expansions/s\n",
      "Timestep: 7\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t113.93 seconds,   \t6889 state expanded (0.16 unique) \t ~60.47 expansions/s\n",
      "Timestep: 8\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t115.32 seconds,   \t6888 state expanded (0.16 unique) \t ~59.73 expansions/s\n",
      "Timestep: 9\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t110.06 seconds,   \t6887 state expanded (0.16 unique) \t ~62.58 expansions/s\n",
      "Timestep: 10\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t111.54 seconds,   \t6886 state expanded (0.16 unique) \t ~61.74 expansions/s\n",
      "Timestep: 11\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t144.20 seconds,   \t6885 state expanded (0.16 unique) \t ~47.75 expansions/s\n",
      "Timestep: 12\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t137.08 seconds,   \t6884 state expanded (0.16 unique) \t ~50.22 expansions/s\n",
      "Timestep: 13\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t109.62 seconds,   \t6883 state expanded (0.16 unique) \t ~62.79 expansions/s\n",
      "Timestep: 14\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t110.48 seconds,   \t6882 state expanded (0.16 unique) \t ~62.29 expansions/s\n",
      "Timestep: 15\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t114.22 seconds,   \t6890 state expanded (0.16 unique) \t ~60.32 expansions/s\n",
      "Timestep: 16\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t111.63 seconds,   \t6882 state expanded (0.16 unique) \t ~61.65 expansions/s\n",
      "Timestep: 17\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t110.29 seconds,   \t6858 state expanded (0.16 unique) \t ~62.18 expansions/s\n",
      "Timestep: 18\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t107.60 seconds,   \t6656 state expanded (0.16 unique) \t ~61.86 expansions/s\n",
      "Timestep: 19\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t105.81 seconds,   \t6629 state expanded (0.16 unique) \t ~62.65 expansions/s\n",
      "Timestep: 20\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t106.41 seconds,   \t6653 state expanded (0.16 unique) \t ~62.52 expansions/s\n",
      "Timestep: 21\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t105.08 seconds,   \t6463 state expanded (0.16 unique) \t ~61.50 expansions/s\n",
      "Timestep: 22\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t102.49 seconds,   \t6171 state expanded (0.16 unique) \t ~60.21 expansions/s\n",
      "Timestep: 23\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ←dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t104.26 seconds,   \t6449 state expanded (0.16 unique) \t ~61.86 expansions/s\n",
      "Timestep: 24\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t98.26 seconds,   \t6016 state expanded (0.16 unique) \t ~61.23 expansions/s\n",
      "Timestep: 25\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t94.19 seconds,   \t5866 state expanded (0.16 unique) \t ~62.28 expansions/s\n",
      "Timestep: 26\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t86.18 seconds,   \t4856 state expanded (0.16 unique) \t ~56.35 expansions/s\n",
      "Timestep: 27\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t88.87 seconds,   \t5000 state expanded (0.16 unique) \t ~56.26 expansions/s\n",
      "Timestep: 28\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D →1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t87.37 seconds,   \t4863 state expanded (0.16 unique) \t ~55.66 expansions/s\n",
      "Timestep: 29\n",
      "Joint action taken: ('↓', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ↑1Xo↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t85.87 seconds,   \t4879 state expanded (0.17 unique) \t ~56.82 expansions/s\n",
      "Timestep: 30\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ↑1Xo←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t103.16 seconds,   \t6361 state expanded (0.18 unique) \t ~61.66 expansions/s\n",
      "Timestep: 31\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ↑1X ←oX \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t66.37 seconds,   \t4473 state expanded (0.17 unique) \t ~67.40 expansions/s\n",
      "Timestep: 32\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑oP \n",
      "O ↑1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t66.29 seconds,   \t4473 state expanded (0.17 unique) \t ~67.48 expansions/s\n",
      "Timestep: 33\n",
      "Joint action taken: ('→', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →oP \n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t66.29 seconds,   \t4470 state expanded (0.17 unique) \t ~67.43 expansions/s\n",
      "Timestep: 34\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø-\n",
      "O ←oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t56.62 seconds,   \t3823 state expanded (0.17 unique) \t ~67.52 expansions/s\n",
      "Timestep: 35\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø-\n",
      "O ←oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t56.21 seconds,   \t3828 state expanded (0.17 unique) \t ~68.11 expansions/s\n",
      "Timestep: 36\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø-\n",
      "O ←oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t56.27 seconds,   \t3802 state expanded (0.17 unique) \t ~67.57 expansions/s\n",
      "Timestep: 37\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø-\n",
      "O →oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t56.34 seconds,   \t3774 state expanded (0.17 unique) \t ~66.98 expansions/s\n",
      "Timestep: 38\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø-\n",
      "O →1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t56.79 seconds,   \t3783 state expanded (0.17 unique) \t ~66.61 expansions/s\n",
      "Timestep: 39\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø-\n",
      "O →1Xo↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t48.62 seconds,   \t3335 state expanded (0.20 unique) \t ~68.60 expansions/s\n",
      "Timestep: 40\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø-\n",
      "O →1Xo←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t54.10 seconds,   \t3759 state expanded (0.18 unique) \t ~69.49 expansions/s\n",
      "Timestep: 41\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø-\n",
      "O ←1X ←oX \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t38.59 seconds,   \t2790 state expanded (0.20 unique) \t ~72.29 expansions/s\n",
      "Timestep: 42\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑oø-\n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t38.49 seconds,   \t2790 state expanded (0.20 unique) \t ~72.48 expansions/s\n",
      "Timestep: 43\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →oø-\n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t38.28 seconds,   \t2774 state expanded (0.20 unique) \t ~72.47 expansions/s\n",
      "Timestep: 44\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø=\n",
      "O ←oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t35.85 seconds,   \t2614 state expanded (0.19 unique) \t ~72.92 expansions/s\n",
      "Timestep: 45\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø=\n",
      "O →oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t35.52 seconds,   \t2587 state expanded (0.19 unique) \t ~72.83 expansions/s\n",
      "Timestep: 46\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø=\n",
      "O →1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t35.21 seconds,   \t2578 state expanded (0.19 unique) \t ~73.22 expansions/s\n",
      "Timestep: 47\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø=\n",
      "O →1Xo↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t25.18 seconds,   \t1810 state expanded (0.23 unique) \t ~71.88 expansions/s\n",
      "Timestep: 48\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø=\n",
      "O →1Xo←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t27.33 seconds,   \t1528 state expanded (0.27 unique) \t ~55.91 expansions/s\n",
      "Timestep: 49\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø=\n",
      "O ←1X ←oX \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t14.13 seconds,   \t1018 state expanded (0.23 unique) \t ~72.06 expansions/s\n",
      "Timestep: 50\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑oø=\n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t13.92 seconds,   \t1018 state expanded (0.23 unique) \t ~73.15 expansions/s\n",
      "Timestep: 51\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →oø=\n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t13.82 seconds,   \t1011 state expanded (0.23 unique) \t ~73.16 expansions/s\n",
      "Timestep: 52\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø1\n",
      "O ←oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t13.06 seconds,   \t980 state expanded (0.23 unique) \t ~75.04 expansions/s\n",
      "Timestep: 53\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø2\n",
      "O →oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t12.99 seconds,   \t948 state expanded (0.23 unique) \t ~72.98 expansions/s\n",
      "Timestep: 54\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0ø3\n",
      "O →oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t11.96 seconds,   \t795 state expanded (0.26 unique) \t ~66.45 expansions/s\n",
      "Timestep: 55\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø4\n",
      "O →oX ↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t11.11 seconds,   \t648 state expanded (0.29 unique) \t ~58.31 expansions/s\n",
      "Timestep: 56\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0ø5\n",
      "O →oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t10.63 seconds,   \t583 state expanded (0.29 unique) \t ~54.85 expansions/s\n",
      "Timestep: 57\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0ø6\n",
      "O →1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t10.32 seconds,   \t485 state expanded (0.33 unique) \t ~47.01 expansions/s\n",
      "Timestep: 58\n",
      "Joint action taken: ('↓', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø7\n",
      "O   Xo↓0X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t8.88 seconds,   \t370 state expanded (0.39 unique) \t ~41.68 expansions/s\n",
      "Timestep: 59\n",
      "Joint action taken: ('↓', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø8\n",
      "O   Xo  X \n",
      "D ←1Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t6.07 seconds,   \t277 state expanded (0.42 unique) \t ~45.60 expansions/s\n",
      "Timestep: 60\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø9\n",
      "O   Xo  X \n",
      "D ←1Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.73 seconds,   \t239 state expanded (0.42 unique) \t ~50.51 expansions/s\n",
      "Timestep: 61\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø10\n",
      "O   Xo↑0X \n",
      "D ←dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.23 seconds,   \t112 state expanded (0.64 unique) \t ~26.46 expansions/s\n",
      "Timestep: 62\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø11\n",
      "O   Xo←0X \n",
      "D ←dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.62 seconds,   \t90 state expanded (0.68 unique) \t ~24.89 expansions/s\n",
      "Timestep: 63\n",
      "Joint action taken: ('↓', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   ø12\n",
      "O ↑dXo  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.70 seconds,   \t49 state expanded (0.65 unique) \t ~28.83 expansions/s\n",
      "Timestep: 64\n",
      "Joint action taken: ('←', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dX   ø13\n",
      "O   Xo  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.39 seconds,   \t42 state expanded (0.64 unique) \t ~30.32 expansions/s\n",
      "Timestep: 65\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dX   ø14\n",
      "O   Xo  X \n",
      "D   X ←dX \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.38 seconds,   \t27 state expanded (0.48 unique) \t ~70.19 expansions/s\n",
      "Timestep: 66\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dX   ø15\n",
      "O   Xo↑dX \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.36 seconds,   \t27 state expanded (0.48 unique) \t ~75.75 expansions/s\n",
      "Timestep: 67\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dX ↑dø16\n",
      "O   Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.33 seconds,   \t27 state expanded (0.48 unique) \t ~80.73 expansions/s\n",
      "Timestep: 68\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →dX ↑dø17\n",
      "O   Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.21 seconds,   \t16 state expanded (0.69 unique) \t ~77.43 expansions/s\n",
      "Timestep: 69\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →dX →dø18\n",
      "O   Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.13 seconds,   \t11 state expanded (0.82 unique) \t ~87.94 expansions/s\n",
      "Timestep: 70\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →dX →dø19\n",
      "O   Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.06 seconds,   \t6 state expanded (1.00 unique) \t ~95.52 expansions/s\n",
      "Timestep: 71\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →dX →dø20\n",
      "O   Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.03 seconds,   \t3 state expanded (1.00 unique) \t ~88.22 expansions/s\n",
      "Timestep: 72\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →1Xd→sP \n",
      "O   Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.03 seconds,   \t2 state expanded (1.00 unique) \t ~65.93 expansions/s\n",
      "Timestep: 73\n",
      "Joint action taken: ('↓', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓1Xo↓sX \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.02 seconds,   \t2 state expanded (1.00 unique) \t ~107.21 expansions/s\n",
      "Timestep: 74\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓1Xo  X \n",
      "D   X ↓sX \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.01 seconds,   \t2 state expanded (1.00 unique) \t ~200.00 expansions/s\n",
      "Timestep: 75\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 20 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓1Xo  X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t109.71 seconds,   \t14584 state expanded (0.19 unique) \t ~132.94 expansions/s\n",
      "Timestep: 76\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓1Xo↑0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t110.45 seconds,   \t14584 state expanded (0.19 unique) \t ~132.05 expansions/s\n",
      "Timestep: 77\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t110.50 seconds,   \t14529 state expanded (0.19 unique) \t ~131.48 expansions/s\n",
      "Timestep: 78\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t103.31 seconds,   \t13608 state expanded (0.19 unique) \t ~131.72 expansions/s\n",
      "Timestep: 79\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t103.49 seconds,   \t13598 state expanded (0.19 unique) \t ~131.40 expansions/s\n",
      "Timestep: 80\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t103.44 seconds,   \t13603 state expanded (0.19 unique) \t ~131.50 expansions/s\n",
      "Timestep: 81\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←oXo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t103.23 seconds,   \t13530 state expanded (0.19 unique) \t ~131.07 expansions/s\n",
      "Timestep: 82\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O →oXo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t108.27 seconds,   \t13816 state expanded (0.19 unique) \t ~127.61 expansions/s\n",
      "Timestep: 83\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O →oXo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t91.34 seconds,   \t12030 state expanded (0.20 unique) \t ~131.71 expansions/s\n",
      "Timestep: 84\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O →oXo↓0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t92.38 seconds,   \t11980 state expanded (0.20 unique) \t ~129.68 expansions/s\n",
      "Timestep: 85\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O →oXo←0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t90.62 seconds,   \t11798 state expanded (0.20 unique) \t ~130.19 expansions/s\n",
      "Timestep: 86\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O →1Xo←oX \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t84.75 seconds,   \t11098 state expanded (0.20 unique) \t ~130.95 expansions/s\n",
      "Timestep: 87\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑oP \n",
      "O ←1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t85.00 seconds,   \t11098 state expanded (0.20 unique) \t ~130.57 expansions/s\n",
      "Timestep: 88\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t43.85 seconds,   \t5477 state expanded (0.19 unique) \t ~124.90 expansions/s\n",
      "Timestep: 89\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd  P \n",
      "O ←1Xo↓0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t44.01 seconds,   \t5277 state expanded (0.19 unique) \t ~119.91 expansions/s\n",
      "Timestep: 90\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd  P \n",
      "O ←1Xo←0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t46.91 seconds,   \t5476 state expanded (0.20 unique) \t ~116.74 expansions/s\n",
      "Timestep: 91\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd  P \n",
      "O ←oX ←oX \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t23.81 seconds,   \t2724 state expanded (0.18 unique) \t ~114.38 expansions/s\n",
      "Timestep: 92\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd↑oP \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t23.87 seconds,   \t2724 state expanded (0.18 unique) \t ~114.13 expansions/s\n",
      "Timestep: 93\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t21.45 seconds,   \t2311 state expanded (0.18 unique) \t ~107.76 expansions/s\n",
      "Timestep: 94\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t21.30 seconds,   \t2293 state expanded (0.18 unique) \t ~107.63 expansions/s\n",
      "Timestep: 95\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t21.23 seconds,   \t2273 state expanded (0.18 unique) \t ~107.04 expansions/s\n",
      "Timestep: 96\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd↑0P \n",
      "O →1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t21.15 seconds,   \t2230 state expanded (0.18 unique) \t ~105.43 expansions/s\n",
      "Timestep: 97\n",
      "Joint action taken: ('↓', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd  P \n",
      "O   Xo↓0X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t15.65 seconds,   \t1736 state expanded (0.21 unique) \t ~110.93 expansions/s\n",
      "Timestep: 98\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd  P \n",
      "O   Xo←0X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t12.98 seconds,   \t1521 state expanded (0.23 unique) \t ~117.21 expansions/s\n",
      "Timestep: 99\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd  P \n",
      "O   X ←oX \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.43 seconds,   \t646 state expanded (0.21 unique) \t ~145.70 expansions/s\n",
      "Timestep: 100\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd↑oP \n",
      "O   X   X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.45 seconds,   \t646 state expanded (0.21 unique) \t ~145.23 expansions/s\n",
      "Timestep: 101\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø1X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.12 seconds,   \t590 state expanded (0.21 unique) \t ~143.21 expansions/s\n",
      "Timestep: 102\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø2X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.89 seconds,   \t564 state expanded (0.21 unique) \t ~144.83 expansions/s\n",
      "Timestep: 103\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø3X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.08 seconds,   \t571 state expanded (0.20 unique) \t ~140.08 expansions/s\n",
      "Timestep: 104\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø4X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.09 seconds,   \t549 state expanded (0.20 unique) \t ~134.27 expansions/s\n",
      "Timestep: 105\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø5X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.93 seconds,   \t528 state expanded (0.20 unique) \t ~134.46 expansions/s\n",
      "Timestep: 106\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø6X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.95 seconds,   \t504 state expanded (0.20 unique) \t ~127.62 expansions/s\n",
      "Timestep: 107\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø7X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.87 seconds,   \t453 state expanded (0.22 unique) \t ~117.09 expansions/s\n",
      "Timestep: 108\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø8X \n",
      "O   Xd←0P \n",
      "O   X   X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.10 seconds,   \t303 state expanded (0.25 unique) \t ~97.87 expansions/s\n",
      "Timestep: 109\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø9X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.51 seconds,   \t351 state expanded (0.24 unique) \t ~100.14 expansions/s\n",
      "Timestep: 110\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø10X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D →1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2.98 seconds,   \t243 state expanded (0.27 unique) \t ~81.55 expansions/s\n",
      "Timestep: 111\n",
      "Joint action taken: ('↓', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø11X \n",
      "O   Xd  P \n",
      "O ↑1X ↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2.50 seconds,   \t152 state expanded (0.32 unique) \t ~60.76 expansions/s\n",
      "Timestep: 112\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø12X \n",
      "O ↑1Xd↑0P \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2.52 seconds,   \t132 state expanded (0.33 unique) \t ~52.46 expansions/s\n",
      "Timestep: 113\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø13X \n",
      "O ↑1Xd←0P \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.97 seconds,   \t94 state expanded (0.37 unique) \t ~47.64 expansions/s\n",
      "Timestep: 114\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø14X \n",
      "O ↑1X ←dP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.58 seconds,   \t53 state expanded (0.32 unique) \t ~90.75 expansions/s\n",
      "Timestep: 115\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø15X \n",
      "O ↑1X →dP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.51 seconds,   \t43 state expanded (0.33 unique) \t ~83.53 expansions/s\n",
      "Timestep: 116\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø16X \n",
      "O ↑1X ↑dP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.42 seconds,   \t28 state expanded (0.43 unique) \t ~67.25 expansions/s\n",
      "Timestep: 117\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø17X \n",
      "O ←1X ↑dP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.31 seconds,   \t18 state expanded (0.56 unique) \t ~57.62 expansions/s\n",
      "Timestep: 118\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø18X \n",
      "O ←1X →dP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.17 seconds,   \t10 state expanded (0.80 unique) \t ~58.95 expansions/s\n",
      "Timestep: 119\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø19X \n",
      "O ←1X ↑dP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.09 seconds,   \t6 state expanded (1.00 unique) \t ~64.34 expansions/s\n",
      "Timestep: 120\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø20X \n",
      "O ←1X ↑dP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.04 seconds,   \t3 state expanded (1.00 unique) \t ~70.11 expansions/s\n",
      "Timestep: 121\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←oX ↑sP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.04 seconds,   \t2 state expanded (1.00 unique) \t ~55.32 expansions/s\n",
      "Timestep: 122\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oX   P \n",
      "O   X ↓sX \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.02 seconds,   \t2 state expanded (1.00 unique) \t ~94.24 expansions/s\n",
      "Timestep: 123\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →1Xo  P \n",
      "O   X   X \n",
      "D   Xd↓sX \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.01 seconds,   \t2 state expanded (1.00 unique) \t ~200.00 expansions/s\n",
      "Timestep: 124\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 20 + shape * 0 \n",
      "X X X P X \n",
      "O →1Xo  P \n",
      "O   X   X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05492A048>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C7B548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C7B988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C7BE88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544077C8>, 'interact')]})), ((('interact', (0, -1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C0F388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C0F088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C0FB48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B54B48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C0FB48>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 125\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →1Xo  P \n",
      "O   X   X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052CCED08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B31C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052CCE788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05492A808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052CCE8C8>, 'interact')]})), ((('interact', (0, -1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C5A388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C5AFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C5A648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C623C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C5A648>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 126\n",
      "Joint action taken: ('←', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←1Xo  P \n",
      "O   X   X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t143.60 seconds,   \t9774 state expanded (0.17 unique) \t ~68.06 expansions/s\n",
      "Timestep: 127\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←1Xo  P \n",
      "O   X ↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t134.27 seconds,   \t9643 state expanded (0.17 unique) \t ~71.82 expansions/s\n",
      "Timestep: 128\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←1Xo↑0P \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t134.70 seconds,   \t9727 state expanded (0.17 unique) \t ~72.21 expansions/s\n",
      "Timestep: 129\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←oXo↑0P \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t134.97 seconds,   \t9423 state expanded (0.17 unique) \t ~69.81 expansions/s\n",
      "Timestep: 130\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXo↑0P \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t146.11 seconds,   \t9847 state expanded (0.17 unique) \t ~67.39 expansions/s\n",
      "Timestep: 131\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXo↑0P \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t126.69 seconds,   \t8798 state expanded (0.18 unique) \t ~69.44 expansions/s\n",
      "Timestep: 132\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXo←0P \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t113.99 seconds,   \t7774 state expanded (0.18 unique) \t ~68.20 expansions/s\n",
      "Timestep: 133\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oX ←oP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t78.06 seconds,   \t5299 state expanded (0.17 unique) \t ~67.89 expansions/s\n",
      "Timestep: 134\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →1Xo↑oP \n",
      "O   X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t76.03 seconds,   \t5142 state expanded (0.17 unique) \t ~67.63 expansions/s\n",
      "Timestep: 135\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ↓1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t62.23 seconds,   \t3810 state expanded (0.17 unique) \t ~61.23 expansions/s\n",
      "Timestep: 136\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ↓1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t63.39 seconds,   \t3751 state expanded (0.17 unique) \t ~59.17 expansions/s\n",
      "Timestep: 137\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ↓1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t63.66 seconds,   \t3756 state expanded (0.18 unique) \t ~59.00 expansions/s\n",
      "Timestep: 138\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ↓1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t59.52 seconds,   \t3358 state expanded (0.18 unique) \t ~56.42 expansions/s\n",
      "Timestep: 139\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t57.59 seconds,   \t3246 state expanded (0.19 unique) \t ~56.37 expansions/s\n",
      "Timestep: 140\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t54.92 seconds,   \t3076 state expanded (0.19 unique) \t ~56.01 expansions/s\n",
      "Timestep: 141\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t52.31 seconds,   \t3127 state expanded (0.19 unique) \t ~59.78 expansions/s\n",
      "Timestep: 142\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ←1X   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t46.55 seconds,   \t2922 state expanded (0.18 unique) \t ~62.78 expansions/s\n",
      "Timestep: 143\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo↑0P \n",
      "O ←oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t43.67 seconds,   \t2620 state expanded (0.19 unique) \t ~60.00 expansions/s\n",
      "Timestep: 144\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xo←0P \n",
      "O →oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t84.28 seconds,   \t3937 state expanded (0.22 unique) \t ~46.71 expansions/s\n",
      "Timestep: 145\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←oP \n",
      "O →1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t29.48 seconds,   \t2226 state expanded (0.20 unique) \t ~75.51 expansions/s\n",
      "Timestep: 146\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑oP \n",
      "O →1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t29.22 seconds,   \t2211 state expanded (0.20 unique) \t ~75.66 expansions/s\n",
      "Timestep: 147\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   X ↑0P \n",
      "O →1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t26.51 seconds,   \t2111 state expanded (0.20 unique) \t ~79.64 expansions/s\n",
      "Timestep: 148\n",
      "Joint action taken: ('↓', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   X   P \n",
      "O   Xo↓0X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t19.37 seconds,   \t1609 state expanded (0.23 unique) \t ~83.06 expansions/s\n",
      "Timestep: 149\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   X   P \n",
      "O   Xo←0X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t16.31 seconds,   \t1313 state expanded (0.25 unique) \t ~80.52 expansions/s\n",
      "Timestep: 150\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   X   P \n",
      "O   X ←oX \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t6.85 seconds,   \t912 state expanded (0.20 unique) \t ~133.14 expansions/s\n",
      "Timestep: 151\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   X ↑oP \n",
      "O   X   X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t6.73 seconds,   \t912 state expanded (0.20 unique) \t ~135.44 expansions/s\n",
      "Timestep: 152\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø1X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t6.26 seconds,   \t891 state expanded (0.20 unique) \t ~142.25 expansions/s\n",
      "Timestep: 153\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø2X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t5.74 seconds,   \t787 state expanded (0.20 unique) \t ~137.10 expansions/s\n",
      "Timestep: 154\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø3X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t5.25 seconds,   \t691 state expanded (0.20 unique) \t ~131.63 expansions/s\n",
      "Timestep: 155\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø4X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t5.00 seconds,   \t632 state expanded (0.21 unique) \t ~126.50 expansions/s\n",
      "Timestep: 156\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø5X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D ←dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.08 seconds,   \t424 state expanded (0.24 unique) \t ~103.80 expansions/s\n",
      "Timestep: 157\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø6X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.33 seconds,   \t301 state expanded (0.27 unique) \t ~90.35 expansions/s\n",
      "Timestep: 158\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø7X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2.55 seconds,   \t181 state expanded (0.33 unique) \t ~70.97 expansions/s\n",
      "Timestep: 159\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø8X \n",
      "O   X   P \n",
      "O   X ↓0X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2.49 seconds,   \t162 state expanded (0.36 unique) \t ~65.15 expansions/s\n",
      "Timestep: 160\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø9X \n",
      "O   X   P \n",
      "O   X   X \n",
      "D →dXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2.17 seconds,   \t127 state expanded (0.41 unique) \t ~58.42 expansions/s\n",
      "Timestep: 161\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø10X \n",
      "O   X   P \n",
      "O ↑dX ↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.85 seconds,   \t78 state expanded (0.58 unique) \t ~42.24 expansions/s\n",
      "Timestep: 162\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø11X \n",
      "O   X   P \n",
      "O ↑dX   X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.61 seconds,   \t65 state expanded (0.49 unique) \t ~40.39 expansions/s\n",
      "Timestep: 163\n",
      "Joint action taken: ('←', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø12X \n",
      "O ↑dX   P \n",
      "O   X   X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.34 seconds,   \t62 state expanded (0.47 unique) \t ~46.22 expansions/s\n",
      "Timestep: 164\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø13X \n",
      "O ↑dX   P \n",
      "O   X   X \n",
      "D   X ←dX \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.37 seconds,   \t41 state expanded (0.34 unique) \t ~110.02 expansions/s\n",
      "Timestep: 165\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø14X \n",
      "O ↑dX   P \n",
      "O   X ↑dX \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.35 seconds,   \t41 state expanded (0.34 unique) \t ~116.00 expansions/s\n",
      "Timestep: 166\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø15X \n",
      "O ↑dX ↑dP \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.41 seconds,   \t41 state expanded (0.34 unique) \t ~99.24 expansions/s\n",
      "Timestep: 167\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø16X \n",
      "O →dX →dP \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.30 seconds,   \t27 state expanded (0.44 unique) \t ~88.64 expansions/s\n",
      "Timestep: 168\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø17X \n",
      "O →1Xd→dP \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.17 seconds,   \t16 state expanded (0.62 unique) \t ~91.62 expansions/s\n",
      "Timestep: 169\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø18X \n",
      "O →1Xd↑dP \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.13 seconds,   \t11 state expanded (0.73 unique) \t ~83.89 expansions/s\n",
      "Timestep: 170\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø19X \n",
      "O →1Xd↑dP \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.06 seconds,   \t6 state expanded (0.83 unique) \t ~96.59 expansions/s\n",
      "Timestep: 171\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø20X \n",
      "O ←1Xd↑dP \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.02 seconds,   \t3 state expanded (1.00 unique) \t ~135.98 expansions/s\n",
      "Timestep: 172\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←1Xd↑sP \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.02 seconds,   \t2 state expanded (1.00 unique) \t ~117.50 expansions/s\n",
      "Timestep: 173\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←1Xd  P \n",
      "O   X ↓sX \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.02 seconds,   \t2 state expanded (1.00 unique) \t ~118.52 expansions/s\n",
      "Timestep: 174\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←1Xd  P \n",
      "O   X   X \n",
      "D   X ↓sX \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.01 seconds,   \t2 state expanded (1.00 unique) \t ~200.00 expansions/s\n",
      "Timestep: 175\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 20 + shape * 0 \n",
      "X X X P X \n",
      "O ←oXd  P \n",
      "O   X   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CC8F88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CC8A88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CC8B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CC8388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B24308>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E59F88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A408C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A40D48>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A40D48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F5AEC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 176\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X   X \n",
      "D   X →0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386DD08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D108>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D4C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534100C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A70708>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBC208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBCE48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBC888>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBC888>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054832408>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 177\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X   X \n",
      "D   X →0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054918808>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FA2A88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FA2D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FA2808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FA2C88>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BA2BC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B3F748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B3FB08>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B3FB08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BA2088>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 178\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X   X \n",
      "D   X →0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479B088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479B688>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479BEC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B21988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479BC88>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053391808>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBE3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBECC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBECC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053391E08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 179\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X   X \n",
      "D   X →0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFDBC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFDF08>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFD148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFD548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053124748>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053480248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053480908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053480488>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053480488>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538F0388>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 180\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B83348>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B831C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B83788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B832C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05311BD48>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B17748>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE608>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE608>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE348>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 181\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054120208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054120EC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054120E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055B565C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055B56808>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417A048>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417A788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417A588>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417A588>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417AFC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 182\n",
      "Joint action taken: ('←', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←oXd  P \n",
      "O   X   X \n",
      "D   X ←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055581B48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D6A88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D6788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479C108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580BEB48>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A9488>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A94C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A9EC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A9EC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A9508>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 183\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←oXd  P \n",
      "O   X   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0CB48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0CF88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0C148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0C7C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055248108>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05395CC48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A65B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A65208>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A65208>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A65288>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 184\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←oXd  P \n",
      "O   X   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057437508>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057437D88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0574371C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057437208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054738888>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D9A188>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D9ABC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D9A3C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D9A3C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D9ACC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 185\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ←oXd  P \n",
      "O   X ↑0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057784088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229188>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053378248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057784E48>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A3E588>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A732C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A73B88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A73B88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A73F88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 186\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X ←0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538F04C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D3F48>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05310CFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D3208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05310CB48>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFD1C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFD0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFDA88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFDA88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFD3C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 187\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054922E88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054922F88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054922608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054922CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552656C8>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CBF48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CBA48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CB5C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CB5C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CB508>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 188\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X   X \n",
      "D   X →0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C43308>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E2888>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E27C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E2248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B211C8>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D2908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052826E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052826808>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052826808>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052826848>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 189\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X ↑0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05455F548>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05455FBC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05455F088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05455F948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05455F348>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C2D088>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C2D908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C2D048>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C2D048>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C2DDC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 190\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X ↑0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052976308>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052976108>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052976688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537FAA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537FA7C8>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539DECC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539DE5C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539DE1C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539DE1C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539DE088>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 191\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓oX ↑0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D5A48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C0AF08>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D5B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D55C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C4EA48>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A45A88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A45BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A450C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A450C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A45D48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 192\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ↓oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539DE708>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539DEFC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052826E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052826548>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534E9388>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534E9EC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534E9708>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534E9708>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534E9848>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 193\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓oX ↓0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055041488>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055041648>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055041808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF3B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF3688>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E7248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E7E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E7448>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E7448>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E7748>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 194\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓oX ↓0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05297FA88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05297F908>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05297F708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E44AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E44C48>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558976C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055897EC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055897948>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055897948>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C4F808>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 195\n",
      "Joint action taken: ('←', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑oXd  P \n",
      "O   X ←0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (1, 0))), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806D48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806808>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4B588>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537D1208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537D1208>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537D1148>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537D1AC8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 196\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑oXd  P \n",
      "O   X   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C61D88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4B9C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4B388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4B448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A30048>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DBE08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806788>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806288>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053806A48>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 197\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑oXd  P \n",
      "O   X   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057BF8A08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057BF8148>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537D1A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537D1C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537D1A88>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E5CB88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C436C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C436C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A88BC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C43488>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 198\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑oXd  P \n",
      "O   X   X \n",
      "D   X →0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C1CC48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6D988>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6D408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6DE08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6DB88>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053373288>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053373048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053373908>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053373908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053373C48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 199\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X ↑0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547ACA48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055374A88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055374C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055374248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053386AC8>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DE3548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DE3688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DE3FC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DE3FC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DE3248>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 200\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X ←0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202CC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202D48>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C03388>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530A72C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530A7248>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530A7248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C23608>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 201\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd  P \n",
      "O   X ←0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F402C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F400C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F40848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F40D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548F3608>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202C88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055082948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0550824C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0550824C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05525D048>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 202\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd↑0P \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [onion@(2, 1), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A91708>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D2E48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D2608>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D2A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D21C8>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D2C48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E4C2C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 203\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd→0P \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [onion@(2, 1), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053814EC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053814548>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053814F48>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538143C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053814508>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053814F08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053814808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053814C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053814C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE588>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 204\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oXd←0P \n",
      "O   X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540EF648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540EFE88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369ACC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540EFA48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B48EC8>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543C2848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6788>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6788>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6348>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 205\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd←0P \n",
      "O ↓oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054524048>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054524348>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054524CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054524808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539593C8>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6188>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6D88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6D88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6E08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 206\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd←0P \n",
      "O ↓oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B503C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B50788>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B50AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05348C3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05348CF08>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531144C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A379C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A37908>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A37908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A37808>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 207\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓oX ↓0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053936EC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053936608>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539363C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C27C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C27A08>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580BED88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580BECC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580BE248>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580BE248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538297C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 208\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O ↓oX   X \n",
      "D   X ↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ((0, -1), (1, 0)), ((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 1), soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B20A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFF4C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFFA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFF588>, (0, 1))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C41B48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C41E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C41F88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C41F88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C41208>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 209\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O →oX   X \n",
      "D   X →0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t319.78 seconds,   \t27110 state expanded (0.17 unique) \t ~84.78 expansions/s\n",
      "Timestep: 210\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O →oX ↑0X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t320.74 seconds,   \t27110 state expanded (0.17 unique) \t ~84.52 expansions/s\n",
      "Timestep: 211\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t321.09 seconds,   \t27110 state expanded (0.17 unique) \t ~84.43 expansions/s\n",
      "Timestep: 212\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t313.58 seconds,   \t26592 state expanded (0.17 unique) \t ~84.80 expansions/s\n",
      "Timestep: 213\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O →1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t319.99 seconds,   \t27126 state expanded (0.17 unique) \t ~84.77 expansions/s\n",
      "Timestep: 214\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t330.20 seconds,   \t26465 state expanded (0.17 unique) \t ~80.15 expansions/s\n",
      "Timestep: 215\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t336.26 seconds,   \t26915 state expanded (0.17 unique) \t ~80.04 expansions/s\n",
      "Timestep: 216\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t332.51 seconds,   \t26643 state expanded (0.17 unique) \t ~80.13 expansions/s\n",
      "Timestep: 217\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t326.79 seconds,   \t26093 state expanded (0.17 unique) \t ~79.85 expansions/s\n",
      "Timestep: 218\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t328.44 seconds,   \t26504 state expanded (0.17 unique) \t ~80.70 expansions/s\n",
      "Timestep: 219\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t347.19 seconds,   \t27945 state expanded (0.17 unique) \t ~80.49 expansions/s\n",
      "Timestep: 220\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t317.48 seconds,   \t26025 state expanded (0.17 unique) \t ~81.97 expansions/s\n",
      "Timestep: 221\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t266.11 seconds,   \t20651 state expanded (0.18 unique) \t ~77.60 expansions/s\n",
      "Timestep: 222\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D ←dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t270.32 seconds,   \t21030 state expanded (0.18 unique) \t ~77.80 expansions/s\n",
      "Timestep: 223\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t260.68 seconds,   \t19591 state expanded (0.18 unique) \t ~75.15 expansions/s\n",
      "Timestep: 224\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t278.07 seconds,   \t20778 state expanded (0.18 unique) \t ~74.72 expansions/s\n",
      "Timestep: 225\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t269.38 seconds,   \t20048 state expanded (0.18 unique) \t ~74.42 expansions/s\n",
      "Timestep: 226\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t261.27 seconds,   \t19708 state expanded (0.18 unique) \t ~75.43 expansions/s\n",
      "Timestep: 227\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O   Xo  X \n",
      "D →1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t259.00 seconds,   \t19493 state expanded (0.18 unique) \t ~75.26 expansions/s\n",
      "Timestep: 228\n",
      "Joint action taken: ('interact', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ↑1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t259.12 seconds,   \t19549 state expanded (0.18 unique) \t ~75.44 expansions/s\n",
      "Timestep: 229\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ↑1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t269.51 seconds,   \t19443 state expanded (0.18 unique) \t ~72.14 expansions/s\n",
      "Timestep: 230\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ↑1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t267.32 seconds,   \t19468 state expanded (0.18 unique) \t ~72.83 expansions/s\n",
      "Timestep: 231\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ↑1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t266.64 seconds,   \t19312 state expanded (0.18 unique) \t ~72.43 expansions/s\n",
      "Timestep: 232\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t270.96 seconds,   \t19625 state expanded (0.18 unique) \t ~72.43 expansions/s\n",
      "Timestep: 233\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t259.69 seconds,   \t19011 state expanded (0.18 unique) \t ~73.21 expansions/s\n",
      "Timestep: 234\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t254.45 seconds,   \t19004 state expanded (0.18 unique) \t ~74.69 expansions/s\n",
      "Timestep: 235\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t251.82 seconds,   \t18737 state expanded (0.18 unique) \t ~74.41 expansions/s\n",
      "Timestep: 236\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O ←oXo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t250.86 seconds,   \t18719 state expanded (0.18 unique) \t ~74.62 expansions/s\n",
      "Timestep: 237\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O →oXo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t251.93 seconds,   \t18534 state expanded (0.18 unique) \t ~73.57 expansions/s\n",
      "Timestep: 238\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑0P \n",
      "O →oXo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t234.27 seconds,   \t16972 state expanded (0.19 unique) \t ~72.45 expansions/s\n",
      "Timestep: 239\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O →oXo↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t234.60 seconds,   \t16930 state expanded (0.19 unique) \t ~72.17 expansions/s\n",
      "Timestep: 240\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O →oXo←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t235.48 seconds,   \t16678 state expanded (0.19 unique) \t ~70.82 expansions/s\n",
      "Timestep: 241\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd  P \n",
      "O →1Xo←oX \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t231.57 seconds,   \t15669 state expanded (0.19 unique) \t ~67.66 expansions/s\n",
      "Timestep: 242\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xd↑oP \n",
      "O ←1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t232.50 seconds,   \t15669 state expanded (0.19 unique) \t ~67.39 expansions/s\n",
      "Timestep: 243\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t116.40 seconds,   \t7980 state expanded (0.18 unique) \t ~68.56 expansions/s\n",
      "Timestep: 244\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t117.24 seconds,   \t7853 state expanded (0.18 unique) \t ~66.98 expansions/s\n",
      "Timestep: 245\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd↑0P \n",
      "O ←1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t117.10 seconds,   \t7545 state expanded (0.19 unique) \t ~64.43 expansions/s\n",
      "Timestep: 246\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd↑0P \n",
      "O ←oXo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t114.83 seconds,   \t7244 state expanded (0.19 unique) \t ~63.08 expansions/s\n",
      "Timestep: 247\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd  P \n",
      "O →oXo↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t56.93 seconds,   \t4126 state expanded (0.17 unique) \t ~72.47 expansions/s\n",
      "Timestep: 248\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd  P \n",
      "O →oXo←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t56.94 seconds,   \t4068 state expanded (0.18 unique) \t ~71.45 expansions/s\n",
      "Timestep: 249\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd  P \n",
      "O →oX ←oX \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t46.90 seconds,   \t3482 state expanded (0.17 unique) \t ~74.25 expansions/s\n",
      "Timestep: 250\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   Xd↑oP \n",
      "O →oX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t47.38 seconds,   \t3482 state expanded (0.17 unique) \t ~73.50 expansions/s\n",
      "Timestep: 251\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd↑0P \n",
      "O →1Xo  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t40.47 seconds,   \t3221 state expanded (0.17 unique) \t ~79.58 expansions/s\n",
      "Timestep: 252\n",
      "Joint action taken: ('↓', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd  P \n",
      "O   Xo↓0X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t30.31 seconds,   \t2563 state expanded (0.18 unique) \t ~84.57 expansions/s\n",
      "Timestep: 253\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd  P \n",
      "O   Xo←0X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t25.80 seconds,   \t2286 state expanded (0.20 unique) \t ~88.62 expansions/s\n",
      "Timestep: 254\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd  P \n",
      "O   X ←oX \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t10.67 seconds,   \t1397 state expanded (0.18 unique) \t ~130.90 expansions/s\n",
      "Timestep: 255\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø=X \n",
      "O   Xd↑oP \n",
      "O   X   X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t10.57 seconds,   \t1397 state expanded (0.18 unique) \t ~132.20 expansions/s\n",
      "Timestep: 256\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø1X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t9.29 seconds,   \t1343 state expanded (0.17 unique) \t ~144.61 expansions/s\n",
      "Timestep: 257\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø2X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t8.94 seconds,   \t1260 state expanded (0.17 unique) \t ~141.00 expansions/s\n",
      "Timestep: 258\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø3X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t7.44 seconds,   \t959 state expanded (0.19 unique) \t ~128.81 expansions/s\n",
      "Timestep: 259\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø4X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t6.50 seconds,   \t785 state expanded (0.20 unique) \t ~120.81 expansions/s\n",
      "Timestep: 260\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø5X \n",
      "O   Xd←0P \n",
      "O   X   X \n",
      "D ←dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t5.14 seconds,   \t565 state expanded (0.21 unique) \t ~109.91 expansions/s\n",
      "Timestep: 261\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø6X \n",
      "O   Xd↑0P \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t5.00 seconds,   \t518 state expanded (0.22 unique) \t ~103.59 expansions/s\n",
      "Timestep: 262\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø7X \n",
      "O   Xd←0P \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.12 seconds,   \t382 state expanded (0.23 unique) \t ~92.67 expansions/s\n",
      "Timestep: 263\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø8X \n",
      "O   X ←dP \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.84 seconds,   \t172 state expanded (0.16 unique) \t ~205.77 expansions/s\n",
      "Timestep: 264\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø9X \n",
      "O   X →dP \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.80 seconds,   \t162 state expanded (0.16 unique) \t ~202.24 expansions/s\n",
      "Timestep: 265\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø10X \n",
      "O   X ↑dP \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.74 seconds,   \t142 state expanded (0.17 unique) \t ~190.81 expansions/s\n",
      "Timestep: 266\n",
      "Joint action taken: ('interact', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø11X \n",
      "O   X ↑dP \n",
      "O ↑dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.68 seconds,   \t122 state expanded (0.18 unique) \t ~180.30 expansions/s\n",
      "Timestep: 267\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø12X \n",
      "O   X →dP \n",
      "O ↑dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.71 seconds,   \t102 state expanded (0.20 unique) \t ~143.09 expansions/s\n",
      "Timestep: 268\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø13X \n",
      "O   X →dP \n",
      "O ↑dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.56 seconds,   \t82 state expanded (0.22 unique) \t ~147.25 expansions/s\n",
      "Timestep: 269\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø14X \n",
      "O   X ↑dP \n",
      "O ↑dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.48 seconds,   \t61 state expanded (0.26 unique) \t ~126.78 expansions/s\n",
      "Timestep: 270\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø15X \n",
      "O   X →dP \n",
      "O →dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.43 seconds,   \t42 state expanded (0.33 unique) \t ~98.29 expansions/s\n",
      "Timestep: 271\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø16X \n",
      "O   X ↑dP \n",
      "O →dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.31 seconds,   \t27 state expanded (0.44 unique) \t ~87.40 expansions/s\n",
      "Timestep: 272\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø17X \n",
      "O   X ↑dP \n",
      "O →dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.25 seconds,   \t18 state expanded (0.56 unique) \t ~73.17 expansions/s\n",
      "Timestep: 273\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø18X \n",
      "O   X →dP \n",
      "O →dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.14 seconds,   \t10 state expanded (0.70 unique) \t ~71.93 expansions/s\n",
      "Timestep: 274\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø19X \n",
      "O   X ↑dP \n",
      "O →1Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.09 seconds,   \t6 state expanded (0.83 unique) \t ~68.97 expansions/s\n",
      "Timestep: 275\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø20X \n",
      "O   X ↑dP \n",
      "O ←1Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.04 seconds,   \t3 state expanded (1.00 unique) \t ~78.95 expansions/s\n",
      "Timestep: 276\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑sP \n",
      "O ←1Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.03 seconds,   \t2 state expanded (1.00 unique) \t ~62.50 expansions/s\n",
      "Timestep: 277\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ←1Xd↓sX \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.02 seconds,   \t2 state expanded (1.00 unique) \t ~100.00 expansions/s\n",
      "Timestep: 278\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ←1Xd  X \n",
      "D   Xd↓sX \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.01 seconds,   \t2 state expanded (1.00 unique) \t ~200.00 expansions/s\n",
      "Timestep: 279\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 20 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053818288>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CFD88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF0C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CFF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF508>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229448>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 280\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9D588>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9DC08>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9D6C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9DA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9D208>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055262A08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552620C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055262B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055262B08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552621C8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 281\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05801E6C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053113DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531137C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053113808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053113188>, 'interact')]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29A88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29D48>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 282\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534EBD48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BA448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BA388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054276B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BAE88>, 'interact')]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542761C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05615FE08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05615FA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05615F848>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05615FA08>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 283\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2B808>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2BC48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2B548>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3DF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FAF48>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540D1E88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D0CD48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540D1708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540D1708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D0CAC8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 284\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059621B08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9CF08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9CC88>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059621388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9C148>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053950408>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054BB2508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054BB2BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054BB2BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052997908>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 285\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B1CD108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B1CD988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B1CDA88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B1CDE88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A51E08>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05281B708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05281B788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05281B808>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05281B808>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054774088>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 286\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (1, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058F33F88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2BAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056253688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A94708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A94988>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3DAC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A688>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A688>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3DA48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3D8C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 287\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (1, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053950148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536CA508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E60208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0550AD448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05287EC48>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053316948>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05287ED88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05287ED88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B0B548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B0BFC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 288\n",
      "Joint action taken: ('↑', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (1, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055B9B808>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054044148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054044208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F70F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F70908>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE7C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE408>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE408>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE6C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055B9B048>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 289\n",
      "Joint action taken: ('↓', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, -1))), (((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380BFC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567B6088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057217D88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545243C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C448C8>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFAB88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA848>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA248>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA248>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 290\n",
      "Joint action taken: ('→', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd→0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (1, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2B148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D0CA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2BD88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9C7048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2BA88>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0578DF548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417A608>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417A608>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417ADC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417AE08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 291\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (1, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC85C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534EB288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFD5C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417A208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534EBE88>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D0C208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A8CB88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A8CB88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055275C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055275D48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 292\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd↑0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (1, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053316748>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FAF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FAC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FA388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A947C8>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2B788>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C3208>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C3208>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C36C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9C7EC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 293\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (1, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575C1A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054524EC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054524808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417ABC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05440C1C8>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD1608>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054524108>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054524108>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0550AD608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052997208>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 294\n",
      "Joint action taken: ('←', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ↑oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADC5348>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055B9B508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055B9BB48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CFE88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD1648>, (1, 0))]})), ((((1, 0), 'interact'), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053316448>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053316A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053316388>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053316388>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053316F08>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 295\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ↑oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C5D08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537C2F88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537C2E88>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05371F608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05371F2C8>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537C27C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E2408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E2FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E2FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E2708>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 296\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411CEC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411CE88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C688>, 'interact')]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3D448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3D208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3D908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3D548>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C3D908>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 297\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6E808>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6EC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6EA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6E588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6E308>, 'interact')]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE788>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE8C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE548>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE8C8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 298\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D7408>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054810AC8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280CF08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054810788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280C4C8>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C62E08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C62608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C62408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C62408>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C62F88>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 299\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539AAD88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539AA4C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFC0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539AA1C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539AA788>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A221348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A221A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A221308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A221308>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A221D88>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 300\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05409A908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05409AA48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05409A548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05409A708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05409AA88>, 'interact')]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1AFC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A6C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1AA08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A6C8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 301\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4788>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4408>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B45C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4D48>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C22388>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E5C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E848>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C22848>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 302\n",
      "Joint action taken: ('↓', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053818B08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEEA48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEED08>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEEE88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE408>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BB948>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4E08>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 303\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F35788>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05281B648>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F35548>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E1248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E18C8>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A51248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05440C288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05440CB88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05440CB88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05440CB48>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 304\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BA288>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BAF88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BAC88>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05371F2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542F9608>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541913C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E12C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E14C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E14C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E1908>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 305\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ←oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C03E08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C036C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C03D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C03DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF048>, (1, 0))]})), ((((1, 0), 'interact'), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8F88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8F88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2B948>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 306\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F05088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F05708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F05748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F05C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F05348>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EBFF88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EBF348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EBF4C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EBF4C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EBFC48>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 307\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054810F08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9D588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548109C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9D748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053951108>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053106CC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E4C8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 308\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055473948>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C5DD88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE208>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BA0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BA1C8>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05720F648>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963248>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 309\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539AA088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9CA88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9C548>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9C188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9C488>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29F88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29188>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 310\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9D288>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05744BC88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05744BCC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05744B688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05744B888>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A948>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A0C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A0C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369AF88>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 311\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05347CC88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05347C048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05347C7C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05347C988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05347C508>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B36A88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C54B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C54DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C54DC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C54208>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 312\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, -1)), ((-1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), 'interact'), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BB4C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055092B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FB308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE4788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE4608>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A87288>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF68C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF68C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E5C648>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 313\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, -1)), ((-1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), 'interact'), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF65C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539638C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1388>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEEB88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE308>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE308>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEE208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEEFC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 314\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, -1)), ((-1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), 'interact'), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C16608>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D077C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D07848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528282C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DFD9C8>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543A7C88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9C7C08>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9C7C08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9C7FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9C77C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 315\n",
      "Joint action taken: ('↑', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (1, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05371F108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05371F7C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05371F5C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05393CFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C548C8>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF6648>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056253748>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056253748>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056253108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05801E788>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 316\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, -1)), ((-1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), 'interact'), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052830248>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052830948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E935C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E93848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C553C8>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5808>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5388>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5388>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05492E5C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 317\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), 'interact'), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318E48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318C88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318488>, (0, 0))]})), ((((1, 0), (1, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053106888>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B21F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B21648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B21648>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B21C08>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 318\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (-1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318048>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052813F08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535BA6C8>, (0, 0))]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535BA9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535BA888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535BA0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535BA888>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 319\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DE0348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FBC48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FBFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FB048>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534707C8>, (0, 0))]})), ((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470DC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470EC8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470EC8>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 320\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053818708>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053818C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052CCEB48>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053818F88>, (0, 0))]})), ((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1908>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B36488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1908>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 321\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF3E48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF3B88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF3788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05440C048>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05440CD48>, (0, 0))]})), ((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541722C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541721C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541726C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552628C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541726C8>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 322\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B59148>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B59E48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B59448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05420C748>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B59A88>, (0, 0))]})), ((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D7288>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D7C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D7648>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B4F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D7648>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 323\n",
      "Joint action taken: ('stay', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ↑oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA188>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFABC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BAE88>, (1, 0))]})), ((((1, 0), 'interact'), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1988>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BADC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B18C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B18C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540BAA88>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 324\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536CA548>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EBC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05330D688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DB6648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DB6708>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052828CC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052828A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052828E88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052828E88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C54E88>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 325\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFD148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05420CE48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05420C1C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05420C348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF6B88>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056253E08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF6448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF6288>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF6288>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A3FE88>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 326\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A221888>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052813A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052813408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052813588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528131C8>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542F9848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537C2688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537C2C88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537C2C88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05287E708>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 327\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B24108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05283C188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B242C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542F3048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542F3388>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052EDBB88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052EDBD48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052EDBD48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E5DC8>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 328\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E5C648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053909A48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053909488>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B48208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B488C8>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0546B2C48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0546B2308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0546B2D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0546B2D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0546B2F08>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 329\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543ED348>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543ED1C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543ED2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B597C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B59FC8>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FB288>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFD808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FB888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FB888>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFDF48>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 330\n",
      "Joint action taken: ('→', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, -1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1DBC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5E48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5988>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A3A5788>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541D8308>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053805A48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053805EC8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053805208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053805EC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 331\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, -1)), ((-1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), 'interact'), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0578DC908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0578DC1C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535BA3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D2B6C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E1188>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05612B3C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05724D888>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05724D888>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05612B4C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05612B5C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 332\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, -1)), ((-1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), 'interact'), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05612B0C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CFAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CFF88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9D648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B9D748>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E2D48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05612BA08>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05612BA08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FA788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05612BDC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 333\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, -1)), ((-1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), 'interact'), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E20C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A8F1C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD1448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD1508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE4588>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DDA548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055473908>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055473908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055473048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055473F88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 334\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 1)), ('interact', (0, 1))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, 1), (1, 0)), ((0, 1), (0, -1)), ((-1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), 'interact'), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (0, 1) holding onion@(1, 3)), Objects: [dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F29E88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B369C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B36808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054BB2DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E7EC8>, (0, 1))]})), ((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADC5908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053386048>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053386048>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053386C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053386E08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 335\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (-1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05478F848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539511C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053951808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053951848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053951748>, (0, 0))]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548FA748>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541D83C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053951DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053951548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053951DC8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 336\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (-1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1DB88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1D448>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1D8C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1DAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05305A2C8>, (0, 0))]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1D788>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053470108>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 337\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (-1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE4548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6C08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E672C8>, (0, 0))]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05342EA88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E67508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05342EAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05342EE08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05342EAC8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 338\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), 'interact'), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A688C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A68648>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A68108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963548>, (0, 0))]})), ((((1, 0), (1, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFDB88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFD548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFD3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFD3C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280CD48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 339\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (-1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C16348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B246C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B24608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B24B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C16108>, (0, 0))]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C16C88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC83C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC84C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC83C8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 340\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 1)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding None), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05366B288>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05366B7C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05366B208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534701C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05366B6C8>, (0, 0))]})), ((('interact', (0, 1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534702C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF8C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF9C8>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF9C8>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 341\n",
      "Joint action taken: ('→', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O ↑oXd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (((0, 1), (0, 1)), ((0, 1), (-1, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DFD648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548F3F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548F3108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548F3648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548F39C8>, (1, 0))]})), ((((1, 0), 'interact'), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548F3748>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052976188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05371F948>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05371F948>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052976048>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 342\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CC1088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CF608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CF108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E5C988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF388>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280D208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552621C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552629C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552629C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055262988>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 343\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (-1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D7948>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533745C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D7908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053374B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534707C8>, 'interact')]})), ((((1, 0), (1, 0)), ('interact', (0, 1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543EF2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543EFD08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543EFD08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543EF288>, (0, 1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 344\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, -1)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229B88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229188>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536C3608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543D7908>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538E2D88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05724D308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E93F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E93F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E93408>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 345\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059318608>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C22448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C22688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C22DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05724D948>, 'interact')]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6E48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE6CC8>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 346\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536C3DC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF60C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF69C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF6A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054DF6288>, 'interact')]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4BAC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4B148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4B408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4BC88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4B408>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 347\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((0, 1), 'interact'), ((0, 1), (1, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 1))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (0, -1) holding None), Objects: [dish@(2, 2), onion@(2, 1), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E9188>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E9CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E9A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E9A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8B6C08>, 'interact')]})), ((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D54C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D5B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D5648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D50C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D5648>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 348\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑oX   P \n",
      "O   Xd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C14E08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C14CC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C14A48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CEA048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E66BC8>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057038D88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548101C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054810808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054810808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B39688>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 349\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑oX   P \n",
      "O   Xd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05724DDC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057217108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C21088>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C21608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536CA148>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AFD3A48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057217048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AFD3108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AFD3108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052CF7908>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 350\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑oX   P \n",
      "O   Xd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D13FC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280DE08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280DEC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280DC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0555DD588>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058539188>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058539F48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0585396C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052971208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0585396C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 351\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oX   P \n",
      "O   Xd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DC24C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DC2E08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DC2448>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DC2288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534CCC48>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053824888>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053991C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053991E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053991E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053824648>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 352\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oX   P \n",
      "O   Xd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C624C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C62748>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C62448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B29A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C62148>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (0, -1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054183608>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054183288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B18C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B18C48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280C2C8>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 353\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oX   P \n",
      "O   Xd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054035C48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0592A05C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05420CAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C948>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (0, -1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E59F48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477ED88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C15648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C15648>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477E348>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 354\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →oX   P \n",
      "O   Xd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C4EF48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05348C808>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05348C6C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05348C5C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530F8C08>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (0, -1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05283C4C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057221908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05283C748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05283C748>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057221748>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 355\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O →1Xo  P \n",
      "O   Xd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (0, 1) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053091108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052840F88>, (0, 1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052840E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052840588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05450ECC8>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA4948>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA4608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA4C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA4C88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA4B08>, (1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 356\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O ↓1Xd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C29708>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0586923C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C29608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058692E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C298C8>, 'interact')]})), ((((1, 0), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C29BC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479B048>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479B048>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479B808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05479B548>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 357\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O ↓1Xd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E8948>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CE4388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055275DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055275548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B01648>, 'interact')]})), ((((1, 0), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054905508>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055082AC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055082AC8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0550820C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055082C08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 358\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O ↓1Xd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DE01C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DE04C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DE03C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540440C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DE06C8>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (0, -1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054567B48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B407C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B40C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B40C08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054567BC8>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 359\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O ↓1Xd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059393048>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059393E08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05698A208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0593937C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BDCA88>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (0, -1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C24888>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D2E888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D2E108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D2E108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BDCCC8>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 360\n",
      "Joint action taken: ('↑', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo↑0P \n",
      "O   Xd  X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05507DC08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A87C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A87A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A873C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05507D108>, 'interact')]})), ((('interact', (0, -1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05339FAC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05339F4C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05339FC88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05339FF88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05339FC88>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 361\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo→0P \n",
      "O   Xd  X \n",
      "D ↓1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', 'interact'),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B708C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A91788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B70548>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055338F08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055338708>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055338288>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEBD88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEBC88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEBC88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEBB48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 362\n",
      "Joint action taken: ('↓', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O   Xd↓0X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533878C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E9A2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054709E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054709288>, 'interact')]})), ((((1, 0), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552557C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D29448>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D29448>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D29208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D29A88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 363\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O   Xd←0X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053955DC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053955908>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053955D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053955108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054309908>, (0, 0))]})), ((((1, 0), 'interact'), ('interact', (0, -1))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E37F08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C0BD08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C0B608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C0B608>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B4B788>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 364\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O   Xd  X \n",
      "D ←1Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AFC208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AFC788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528529C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AFC048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053803AC8>, 'interact')]})), ((('interact', (0, -1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05432E688>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540F5248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540F5B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540F5E48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540F5B48>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 365\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O   Xd  X \n",
      "D ←1Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963808>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543EF248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543EF888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053963A08>, 'interact')]})), ((('interact', (0, -1)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05297FE08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05297FF88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05297F088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0588AF188>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05297F088>, (0, -1))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 366\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O   Xd  X \n",
      "D ←dXd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, -1)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A94608>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0546F7508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A9FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A9648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0546F7BC8>, 'interact')]})), ((((1, 0), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0DD08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0DC48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0DC48>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0D908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0DDC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 367\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O ↑dXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053822208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C08748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052852088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C08E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528529C8>, 'interact')]})), ((((1, 0), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053103688>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531035C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531035C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C8288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053103088>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 368\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O ↑dXd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F010C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F01D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F013C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF6B88>, 'interact')]})), ((((1, 0), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053948608>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539482C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539482C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053948208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580BC148>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 369\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O ↑dXd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543A9BC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543A9548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543A9AC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543A9DC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053955A08>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F6D3C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F6D408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F6DAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F6DAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BFB988>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 370\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   Xo  P \n",
      "O ↑dXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, -1)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 1)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', 'interact'),), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C227C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C228C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C22808>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C22C08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CDE88>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CDDC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053BB1588>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053BB1148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053BB1148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BA6B88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 371\n",
      "Joint action taken: ('↓', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dXo  P \n",
      "O   Xd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05800E0C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054713F48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054713608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA4C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537DCF88>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9C848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05395AFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537DC348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537DC348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541F5D48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 372\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dXo  P \n",
      "O   Xd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052CF7C48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05282C948>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C8288>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C8C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05282CD48>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C34448>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05786D8C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530FA308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530FA308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530FAC08>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 373\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dXo  P \n",
      "O   Xd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0546E9588>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052865108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052865888>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052865C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B5C9C8>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CFAC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E3D08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E3548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E3548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537CF208>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 374\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dXo  P \n",
      "O   Xd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D1AB08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05801E5C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05801EB88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552756C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053109248>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CB7388>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0578DCD48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0578DC288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0578DC288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053214AC8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 375\n",
      "Joint action taken: ('→', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O ↑dXo  P \n",
      "O   Xd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (((-1, 0), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((-1, 0), (0, 0)), ('interact', (0, 1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [dish@(2, 3), dish@(2, 2), soup@(4, 1) with state ('onion', 1, 0), dish@(1, 0), dish@(1, 4)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05382C708>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C08188>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C08688>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056643F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C08488>, (0, 0))]})), ((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539A8D08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E050FA3F78>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05382C0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBE608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CBE608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05382C988>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 376\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X XdX P X \n",
      "O ↑1Xo  P \n",
      "O   Xd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t143.49 seconds,   \t8770 state expanded (0.18 unique) \t ~61.12 expansions/s\n",
      "Timestep: 377\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X XdX P X \n",
      "O ←1Xo  P \n",
      "O   Xd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t126.14 seconds,   \t7601 state expanded (0.17 unique) \t ~60.26 expansions/s\n",
      "Timestep: 378\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX P X \n",
      "O ←1Xo↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t123.17 seconds,   \t7655 state expanded (0.17 unique) \t ~62.15 expansions/s\n",
      "Timestep: 379\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX P X \n",
      "O ←1Xo↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t122.09 seconds,   \t7378 state expanded (0.19 unique) \t ~60.43 expansions/s\n",
      "Timestep: 380\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX P X \n",
      "O ←1Xo←0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t121.47 seconds,   \t7472 state expanded (0.19 unique) \t ~61.52 expansions/s\n",
      "Timestep: 381\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X XdX P X \n",
      "O ←oX ←oP \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t108.34 seconds,   \t6431 state expanded (0.20 unique) \t ~59.36 expansions/s\n",
      "Timestep: 382\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X XdX P X \n",
      "O →oX ↑oP \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t109.13 seconds,   \t6391 state expanded (0.20 unique) \t ~58.56 expansions/s\n",
      "Timestep: 383\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X XdX ø-X \n",
      "O →oX ↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t95.65 seconds,   \t5661 state expanded (0.20 unique) \t ~59.19 expansions/s\n",
      "Timestep: 384\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X XdX ø-X \n",
      "O →1Xo↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t95.13 seconds,   \t5595 state expanded (0.20 unique) \t ~58.82 expansions/s\n",
      "Timestep: 385\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX ø-X \n",
      "O →1Xo←0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t99.88 seconds,   \t5604 state expanded (0.18 unique) \t ~56.11 expansions/s\n",
      "Timestep: 386\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X XdX ø-X \n",
      "O ←1X ←oP \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t82.89 seconds,   \t4977 state expanded (0.20 unique) \t ~60.04 expansions/s\n",
      "Timestep: 387\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X XdX ø-X \n",
      "O ←oX ↑oP \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t83.21 seconds,   \t4952 state expanded (0.20 unique) \t ~59.51 expansions/s\n",
      "Timestep: 388\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X XdX ø=X \n",
      "O →oX ↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t78.90 seconds,   \t4716 state expanded (0.20 unique) \t ~59.77 expansions/s\n",
      "Timestep: 389\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X XdX ø=X \n",
      "O →1Xo↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t75.86 seconds,   \t4711 state expanded (0.20 unique) \t ~62.10 expansions/s\n",
      "Timestep: 390\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX ø=X \n",
      "O →1Xo←0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t41.84 seconds,   \t2663 state expanded (0.21 unique) \t ~63.65 expansions/s\n",
      "Timestep: 391\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX ø=X \n",
      "O →1X ←oP \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t20.08 seconds,   \t1502 state expanded (0.21 unique) \t ~74.81 expansions/s\n",
      "Timestep: 392\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X XdX ø=X \n",
      "O ←1X ↑oP \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t19.50 seconds,   \t1442 state expanded (0.21 unique) \t ~73.96 expansions/s\n",
      "Timestep: 393\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX ø1X \n",
      "O ←1X ↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t17.76 seconds,   \t1394 state expanded (0.20 unique) \t ~78.49 expansions/s\n",
      "Timestep: 394\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX ø2X \n",
      "O ←1X ↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t17.13 seconds,   \t1320 state expanded (0.21 unique) \t ~77.04 expansions/s\n",
      "Timestep: 395\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX ø3X \n",
      "O ←1X ↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t16.36 seconds,   \t1246 state expanded (0.21 unique) \t ~76.16 expansions/s\n",
      "Timestep: 396\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X XdX ø4X \n",
      "O ←oX   P \n",
      "O   Xd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t16.08 seconds,   \t1180 state expanded (0.21 unique) \t ~73.39 expansions/s\n",
      "Timestep: 397\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X XdX ø5X \n",
      "O →oX ↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t15.68 seconds,   \t1054 state expanded (0.23 unique) \t ~67.22 expansions/s\n",
      "Timestep: 398\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X XdX ø6X \n",
      "O →oX   P \n",
      "O   Xd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t16.04 seconds,   \t872 state expanded (0.25 unique) \t ~54.36 expansions/s\n",
      "Timestep: 399\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XdX ø7X \n",
      "O →oX ↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [6:24:45<00:00, 23086.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found goal after: \t15.51 seconds,   \t738 state expanded (0.26 unique) \t ~47.59 expansions/s\n",
      "Timestep: 400\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X XdX ø8X \n",
      "O →oX ↑0P \n",
      "O   Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Avg reward 80.00 (std: 0.00, se: 0.00) over 1 games of avg length 400.0\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MediumLevelPlanner from c:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\data\\planners\\random0_am.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "Found goal after: \t37.54 seconds,   \t2397 state expanded (0.32 unique) \t ~63.86 expansions/s\n",
      "Timestep: 1\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.47 seconds,   \t2396 state expanded (0.32 unique) \t ~63.94 expansions/s\n",
      "Timestep: 2\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.65 seconds,   \t2395 state expanded (0.32 unique) \t ~63.61 expansions/s\n",
      "Timestep: 3\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.48 seconds,   \t2394 state expanded (0.32 unique) \t ~63.88 expansions/s\n",
      "Timestep: 4\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ↑1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.55 seconds,   \t2393 state expanded (0.32 unique) \t ~63.72 expansions/s\n",
      "Timestep: 5\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.76 seconds,   \t2392 state expanded (0.32 unique) \t ~63.35 expansions/s\n",
      "Timestep: 6\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t38.33 seconds,   \t2391 state expanded (0.32 unique) \t ~62.38 expansions/s\n",
      "Timestep: 7\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.86 seconds,   \t2390 state expanded (0.32 unique) \t ~63.14 expansions/s\n",
      "Timestep: 8\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←1X   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.36 seconds,   \t2389 state expanded (0.32 unique) \t ~63.95 expansions/s\n",
      "Timestep: 9\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O ←oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.29 seconds,   \t2388 state expanded (0.32 unique) \t ~64.05 expansions/s\n",
      "Timestep: 10\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t38.27 seconds,   \t2387 state expanded (0.32 unique) \t ~62.37 expansions/s\n",
      "Timestep: 11\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.42 seconds,   \t2386 state expanded (0.32 unique) \t ~63.75 expansions/s\n",
      "Timestep: 12\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t37.27 seconds,   \t2385 state expanded (0.32 unique) \t ~64.00 expansions/s\n",
      "Timestep: 13\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →oX   X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t38.58 seconds,   \t2384 state expanded (0.32 unique) \t ~61.80 expansions/s\n",
      "Timestep: 14\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O →1Xo  X \n",
      "D   X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t38.17 seconds,   \t2383 state expanded (0.32 unique) \t ~62.42 expansions/s\n",
      "Timestep: 15\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t68.38 seconds,   \t4654 state expanded (0.19 unique) \t ~68.06 expansions/s\n",
      "Timestep: 16\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t71.31 seconds,   \t4620 state expanded (0.19 unique) \t ~64.79 expansions/s\n",
      "Timestep: 17\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t87.37 seconds,   \t4623 state expanded (0.19 unique) \t ~52.91 expansions/s\n",
      "Timestep: 18\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ↓1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t77.19 seconds,   \t4623 state expanded (0.19 unique) \t ~59.89 expansions/s\n",
      "Timestep: 19\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t94.44 seconds,   \t5287 state expanded (0.19 unique) \t ~55.98 expansions/s\n",
      "Timestep: 20\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xo↓0X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t84.70 seconds,   \t4220 state expanded (0.18 unique) \t ~49.82 expansions/s\n",
      "Timestep: 21\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xo←0X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t100.42 seconds,   \t3896 state expanded (0.18 unique) \t ~38.80 expansions/s\n",
      "Timestep: 22\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ←1X   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t60.16 seconds,   \t3552 state expanded (0.17 unique) \t ~59.04 expansions/s\n",
      "Timestep: 23\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑0P \n",
      "O   Xo  X \n",
      "D ←dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t57.02 seconds,   \t3198 state expanded (0.17 unique) \t ~56.09 expansions/s\n",
      "Timestep: 24\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xo↓0X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t87.91 seconds,   \t4070 state expanded (0.16 unique) \t ~46.30 expansions/s\n",
      "Timestep: 25\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   Xo←0X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t102.60 seconds,   \t4577 state expanded (0.18 unique) \t ~44.61 expansions/s\n",
      "Timestep: 26\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X   P \n",
      "O   X ←oX \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t46.72 seconds,   \t2303 state expanded (0.17 unique) \t ~49.30 expansions/s\n",
      "Timestep: 27\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X P X \n",
      "O   X ↑oP \n",
      "O   X   X \n",
      "D →dX   X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t46.48 seconds,   \t2303 state expanded (0.17 unique) \t ~49.55 expansions/s\n",
      "Timestep: 28\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D →1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t48.31 seconds,   \t2049 state expanded (0.18 unique) \t ~42.41 expansions/s\n",
      "Timestep: 29\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A33908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A33E48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A33948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A33C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059444988>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059444488>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502C3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502CCC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502CCC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594440C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 30\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A03BC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05888D6C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A03588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05888D348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05888DB08>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053241608>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053788988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053788908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053788908>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053788808>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 31\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DD588>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533123C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053312548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0555FA088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053590148>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056286E88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056286988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0562868C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0562868C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0562863C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 32\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   X   X \n",
      "D ←1Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECFC08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB05C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531D2388>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0E808>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280DD08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280D548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280D548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280D7C8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 33\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   X   X \n",
      "D ←dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7748>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059465388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA4388>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DD8C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DDDC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DD588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DD588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DD7C8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 34\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054822208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548229C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548228C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054822888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B39188>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E2708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E2D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E25C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E25C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053803C48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 35\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, 1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8308>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37348>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A379C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37908>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05555DFC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05555D908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05555DF88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05555DF88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05555DAC8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 36\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, 1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BFA30C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5FC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C58C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056289A88>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A6108>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A63C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A6788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A6788>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A6D88>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 37\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   X   X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053311848>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054314248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054314408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053311A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054314388>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B8D7C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B8D688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B8DA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B8DA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B8DDC8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 38\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   X ↓0X \n",
      "D →dXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613B808>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613B608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613B148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613BD08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613BC48>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D788>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477DEC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477DEC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D508>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 39\n",
      "Joint action taken: ('↓', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑dX   X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, -1))), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), 'interact'), ((-1, 0), (0, 1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F15588>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502C8C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502CF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502C908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0D08>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059806248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059806F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059806E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059806E48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C6E048>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 40\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑dX   X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, -1))), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), 'interact'), ((-1, 0), (0, 1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C35E48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C35908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C35C48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C35B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E4DA88>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059317588>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0593178C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059317F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059317F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05888BD88>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 41\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑dX ↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, -1))), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057212E08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057212948>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057212488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057212808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F8ABC8>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053813B88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053813F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053813688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053813688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053813EC8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 42\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑dX ←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, -1))), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ((0, -1), (0, 1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544FC7C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544FC708>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544FC0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544FCF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE208>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D233C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D237C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059444388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059444388>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05618AA48>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 43\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →dX   X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t145.69 seconds,   \t7302 state expanded (0.18 unique) \t ~50.12 expansions/s\n",
      "Timestep: 44\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →dX ↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t153.63 seconds,   \t7328 state expanded (0.18 unique) \t ~47.70 expansions/s\n",
      "Timestep: 45\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →dX   X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t137.18 seconds,   \t7285 state expanded (0.17 unique) \t ~53.11 expansions/s\n",
      "Timestep: 46\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →1Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t136.00 seconds,   \t7259 state expanded (0.18 unique) \t ~53.38 expansions/s\n",
      "Timestep: 47\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O ←1Xd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', 'interact'),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, 1), 'interact'), ((0, 1), (0, -1)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D138C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D13348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D13608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D9C9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D9CA48>, (1, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D13F48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B75408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D9C3C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D9C3C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B75B08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 48\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O ←oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, -1)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), 'interact'), ('interact', (-1, 0))), (('interact', 'interact'),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2AAA08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2AA648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1348>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2AA908>, (1, 0))]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E7FDC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E7F448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E7FD08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380A0C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E7FD08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 49\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', 'interact')), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528485C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052848348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052848788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EAEDC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052848D48>, (1, 0))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CBF088>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CBF788>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CBF4C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CBF4C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B9FFC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 50\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056082048>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053688888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053688408>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05939E3C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053688948>, (-1, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BFCAC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BFCC88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BFCDC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BFCDC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BFC508>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 51\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A70C48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A704C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A708C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD6048>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD6B48>, (-1, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594E6E48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594E6848>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594E6608>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594E6608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05376AF48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 52\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), 'interact'), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058692A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058692E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058692608>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058692D88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1588>, (-1, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572DE148>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572DEF88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572DE548>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572DE548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A8908>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 53\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', 'interact')), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05873EAC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056106588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05873E2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E93E08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B772648>, (1, 0))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058692908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058692C88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0586920C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0586920C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A87688>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 54\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), 'interact'), ((0, -1), (1, 0)), ('interact', (0, 0))), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056106C08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056106588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056106A08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0561069C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056106088>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477DBC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB2C08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB2C48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560EB148>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB2C08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 55\n",
      "Joint action taken: ('→', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B87F4C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0555997C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055599E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055599588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531D2CC8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B976C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B97688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B97848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B97DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B97848>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 56\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E13388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B19848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B19E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572E0048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C35C8>, 'interact')]})), ((((0, -1), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37448>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37088>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37088>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37AC8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 57\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698D48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E67E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529E2888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05874B7C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05874B688>, 'interact')]})), ((((0, -1), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0561430C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05383CEC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05383C948>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05383C948>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056143508>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 58\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O ←oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, -1)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), 'interact'), ('interact', (-1, 0))), (('interact', 'interact'),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EBB08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B10648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B10308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B8D108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B8DC48>, (1, 0))]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05674B648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05674B0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05674B748>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05674BF48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05674B748>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 59\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053909E48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564B3348>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564B3588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564B39C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564B3E08>, (0, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698FC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698308>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 60\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', 'interact')), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539090C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC81C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0555996C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4C48>, (1, 0))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055265348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FEE48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FEB08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FEB08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FEC08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 61\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', 'interact')), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477DA88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD2888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387808>, (1, 0))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053452E08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053452BC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D6F08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D6F08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053452748>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 62\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ('interact', 'interact')), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD2408>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BFF848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BFFB48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BFF108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05402B9C8>, (1, 0))]})), ((((0, -1), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D1EB48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D1E808>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05939EA88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05939EA88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D1E148>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 63\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052826C48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B97288>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528269C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B97BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C0C8>, (0, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C988>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C05C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C0208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C0FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C0208>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 64\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698888>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698F88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698688>, (0, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD6608>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD6508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD6948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B10CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CD6948>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 65\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A488>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1ABC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1E048>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1E548>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CD608>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E9AF08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E9A548>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E9A088>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529E2088>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E9A548>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 66\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F97488>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F97D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E30888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E30E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E98CC8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E98C48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E2888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E13F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E13548>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E13F88>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 67\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EB0C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EBB48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EB088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EBF88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056106848>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0AC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0488>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 68\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CA788>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CA9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557D7E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557D7FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531B0E08>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053909148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DB9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DBC48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DBCC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DBC48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 69\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CD8F88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280C9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1A1C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0598287C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059828188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0595FAC88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0595FA548>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0595FAC88>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 70\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AAC408>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AAC888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AAC1C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AACF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CD8C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB2288>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FEF08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055897188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053739A48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055897188>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 71\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054276848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054276388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054276F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A71348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536C3D88>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387488>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387108>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387B88>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 72\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A88888>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A6E88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0F08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058960108>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529A67C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A71488>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A71B88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D20C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A71488>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 73\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057226E08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594CE948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA05C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594CEAC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544AF348>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7308>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E72C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7E88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7388>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E72C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 74\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A8C388>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A8C908>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7F08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7B48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EAE308>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2F48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2D08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2848>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2F48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 75\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t133.11 seconds,   \t7403 state expanded (0.17 unique) \t ~55.61 expansions/s\n",
      "Timestep: 76\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t134.23 seconds,   \t7355 state expanded (0.17 unique) \t ~54.79 expansions/s\n",
      "Timestep: 77\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.16 seconds,   \t7266 state expanded (0.18 unique) \t ~54.98 expansions/s\n",
      "Timestep: 78\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DCC788>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DCCF88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DCC248>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DCC6C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DCC108>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DCCD08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C66848>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C664C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C661C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C66848>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 79\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635148>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536351C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635108>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BC5908>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05447FD48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05447F988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05447FAC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05447FB88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05447F988>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 80\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B32448>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A716C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058655348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B46308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059799288>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635488>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059686C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059686388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596869C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059686388>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 81\n",
      "Joint action taken: ('←', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd←0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567EB648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558CEA08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E188>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558CED08>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058655A88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F0DBC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F0D988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F0D988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554A1908>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 82\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542029C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055EDBFC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F185C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F9CE48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054924C88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054924B08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533E5C48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533E5708>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054924B08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 83\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054923B88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C828C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C82A88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C82548>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D5C88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B834C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B83CC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B83EC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B83D08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B83CC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 84\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05447F508>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056998C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0569985C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056998AC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055EDBB88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C35508>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C35F48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C35F08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C35708>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C35F48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 85\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053803508>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3EB08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3EF08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C35AC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533875C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533879C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056270748>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053387CC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533879C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 86\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.70 seconds,   \t7247 state expanded (0.18 unique) \t ~55.87 expansions/s\n",
      "Timestep: 87\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C848>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C908>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05284AC48>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C020C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529CD148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C023C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C023C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529CDF48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 88\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059399408>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2DB648>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0593991C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059342DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BAD848>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081588>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0570812C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081748>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 89\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2DB948>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2DBB48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F053C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2DB208>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2DB648>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD5D88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529CDB48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055D88148>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A79148>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055D88148>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 90\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433B888>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433BB48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433B348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613B3C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055451C08>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055D88708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62048>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62E08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62E08>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62988>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 91\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8BE2C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8BE1C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059399088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C508>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05439F988>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05867C948>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05867C1C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05867C748>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05867C748>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05867C408>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 92\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F06908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F06248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F06B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059F46608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059F466C8>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D2A08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D2608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D23C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529D23C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5A048>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 93\n",
      "Joint action taken: ('→', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531D2308>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CCB08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CCA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CCDC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CC8C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFC788>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFC108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFC208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFC508>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFC208>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 94\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B772B88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7721C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B772A88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B772D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057781308>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BDC408>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BDCEC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BDC2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05357FA48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BDCEC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 95\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A6AC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A6288>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A66C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A69C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53E48>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531D2188>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531D2E08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531D26C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538463C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531D2E08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 96\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A683708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056643408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054539308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BDC288>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581AFF88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581AF748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581AFD08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581AFC08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581AFD08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 97\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), 'interact'), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05455A7C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB4148>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB49C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB4BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB4A08>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ED9B48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D19508>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D19508>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 98\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A40108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A40F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A400C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081148>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081788>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081F08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0579B0FC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081808>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081808>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0579B0848>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 99\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB08C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB0B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB0348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052997D48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D9C8>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECFD08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECF848>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECFF48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECFF48>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECF9C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 100\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0579B0EC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057226908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057226A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B952548>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B952988>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053254F48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C0E88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C0788>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C0788>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538C0B88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 101\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055288488>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055288AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB4CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1888>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADB0688>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059659B48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059659C08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596593C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596593C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054D96FC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 102\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), 'interact'), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C727C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C725C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C72548>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C726C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053395108>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056643488>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056643FC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056643248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056643E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056643FC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 103\n",
      "Joint action taken: ('→', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A12288>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A12948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A12C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A122C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538F0708>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D13EC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D13288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D130C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D13A88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D130C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 104\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053846048>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053846408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053846188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053846308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541D3B88>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1F08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B14C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1D88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B14C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 105\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C53A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C535C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C53E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05439FB48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A88288>, 'interact')]})), ((((0, -1), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0559453C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055945848>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055945848>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53688>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 106\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E0DC08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E0D288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E0D108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597302C8>, 'interact')]})), ((((0, -1), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B6DC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D5C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B6408>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B6408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054BF2C48>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 107\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD57C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD5888>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD5188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD51C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0578BB348>, (0, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380AAC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380AFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380AA88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380A908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380AA88>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 108\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05385FC08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD5F88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD5C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477DB08>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054565E08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2AC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 109\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0579B0708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0579B0888>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081C48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1988>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E18C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1608>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A57DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1608>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 110\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62A88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056643CC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2DB7C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057229788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572295C8>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2DBF88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5AB88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5A3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DE0348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5AB88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 111\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A575C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A57448>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A57988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C3E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BAD508>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055539C88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056140B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055539608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055539608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3C08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 112\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C35D48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C35DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C351C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C35788>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C35388>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8CC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D188>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB4088>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477DF08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D188>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 113\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531EB688>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053769408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053769B48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053769508>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053C1AD88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5408>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5B88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5488>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597F7308>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5B88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 114\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536CB708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8408>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8208>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059F46AC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A15F88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059659FC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059659DC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596593C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059659FC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 115\n",
      "Joint action taken: ('↑', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3C08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3D48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3A88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3688>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E14C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05618A1C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53888>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 116\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053884108>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5AB88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5A948>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3E08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B6248>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675B648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054539288>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054539F48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054539388>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054539288>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 117\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567EBE08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055451448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055451FC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055451CC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540E1788>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D57C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057226DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057226448>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572269C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057226DC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 118\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D5988>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62448>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62D48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A62B48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502FB88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502FE88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502F7C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502F788>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502FE88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 119\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.25 seconds,   \t7403 state expanded (0.17 unique) \t ~55.98 expansions/s\n",
      "Timestep: 120\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t133.97 seconds,   \t7355 state expanded (0.17 unique) \t ~54.90 expansions/s\n",
      "Timestep: 121\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730A08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730648>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730288>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730B88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560FA1C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560FA108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560FA748>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560FAB08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560FA108>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 122\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C1D248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C1DF08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C1D988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C1DF88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C1DE88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053468D48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053468988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053468B08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053468D88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053468988>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 123\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AA3A48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AA3CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AA3108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AA3E08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AA32C8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058654788>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058654A88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058654108>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058654848>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058654A88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 124\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A804108>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A804748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB40C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A804608>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059317748>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055965848>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059645F48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055965F08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596453C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059645F48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 125\n",
      "Joint action taken: ('→', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0548ABC08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057250A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057250048>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057250CC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05506DB08>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3E48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3AC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D31C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3448>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3AC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 126\n",
      "Joint action taken: ('stay', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A791C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0559650C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055965288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055965248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575C3C88>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055543208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055543C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055543148>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055543C48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 127\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433B388>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433B288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433BD48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433BD88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535F6488>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057714D48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597309C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597305C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059730E48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 128\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E73FC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E1A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E1908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E16C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055965B88>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E733C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3E08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9D3CC8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 129\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A56EC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A56E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A56E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A56DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF0B88>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054459F88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FEC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FED48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FE1C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FED48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 130\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.10 seconds,   \t7281 state expanded (0.17 unique) \t ~55.12 expansions/s\n",
      "Timestep: 131\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.98 seconds,   \t7291 state expanded (0.18 unique) \t ~55.24 expansions/s\n",
      "Timestep: 132\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t128.59 seconds,   \t7275 state expanded (0.18 unique) \t ~56.58 expansions/s\n",
      "Timestep: 133\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t128.92 seconds,   \t7306 state expanded (0.18 unique) \t ~56.67 expansions/s\n",
      "Timestep: 134\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.02 seconds,   \t7300 state expanded (0.17 unique) \t ~56.14 expansions/s\n",
      "Timestep: 135\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t126.92 seconds,   \t7326 state expanded (0.17 unique) \t ~57.72 expansions/s\n",
      "Timestep: 136\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0E408>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0EA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0E808>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F0E948>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7ECC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7E708>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A3B188>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7E6C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A3BD08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A3B188>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 137\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594496C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059449748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059449BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059449888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059449E88>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545A8DC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545A8088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545A8AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054875588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545A8AC8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 138\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D6C88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D6DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D63C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABCA08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABC548>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CBF208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057394A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D6EC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057394908>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D6EC8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 139\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202608>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AEE7B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058225748>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053254D88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532546C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053254C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053254148>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053254C48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 140\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E79B08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E798C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E79488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E79408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E79CC8>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05281A1C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF07C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF0548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF0488>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF0548>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 141\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4108>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A41C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C8F9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADE76C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540748C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053254B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054074208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540747C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054074208>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 142\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t128.30 seconds,   \t7293 state expanded (0.17 unique) \t ~56.84 expansions/s\n",
      "Timestep: 143\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.69 seconds,   \t7306 state expanded (0.18 unique) \t ~55.90 expansions/s\n",
      "Timestep: 144\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t128.75 seconds,   \t7300 state expanded (0.17 unique) \t ~56.70 expansions/s\n",
      "Timestep: 145\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t127.88 seconds,   \t7326 state expanded (0.17 unique) \t ~57.29 expansions/s\n",
      "Timestep: 146\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.32 seconds,   \t7275 state expanded (0.18 unique) \t ~56.26 expansions/s\n",
      "Timestep: 147\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.77 seconds,   \t7306 state expanded (0.18 unique) \t ~55.45 expansions/s\n",
      "Timestep: 148\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054039948>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED82C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8488>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8B08>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8048>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D19248>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D191C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D19D88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D19248>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 149\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFCB48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059C09B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059C09808>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059C09708>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059C09108>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B36BC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B36088>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B365C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B36648>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B36088>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 150\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05906C908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05906CB88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05906CF48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05906CEC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05906C8C8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05906C148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532056C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532059C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053205908>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532056C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 151\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C5CC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530D1EC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C5C88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C5F88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530D10C8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B23688>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B716C48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B23AC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B716588>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B716C48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 152\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B80508>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B80A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B80748>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A43C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4188>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8D88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8EC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED81C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8D88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 153\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t127.79 seconds,   \t7300 state expanded (0.17 unique) \t ~57.12 expansions/s\n",
      "Timestep: 154\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t127.81 seconds,   \t7326 state expanded (0.17 unique) \t ~57.32 expansions/s\n",
      "Timestep: 155\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.86 seconds,   \t7275 state expanded (0.18 unique) \t ~55.17 expansions/s\n",
      "Timestep: 156\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.30 seconds,   \t7306 state expanded (0.18 unique) \t ~56.50 expansions/s\n",
      "Timestep: 157\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t128.82 seconds,   \t7300 state expanded (0.17 unique) \t ~56.67 expansions/s\n",
      "Timestep: 158\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t128.27 seconds,   \t7326 state expanded (0.17 unique) \t ~57.11 expansions/s\n",
      "Timestep: 159\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730688>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054487188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054487E48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054487488>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054487648>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054487088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055451748>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055451108>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055451D88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055451748>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 160\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543490C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054FD16C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054FD1108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F83BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F83888>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054349088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05548E5C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FE348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544F9C48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FE348>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 161\n",
      "Joint action taken: ('→', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd→0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730E08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564EF308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564EF5C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05445C4C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F2C0C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F2C348>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0549A3808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0549A3F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0549A3AC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0549A3F08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 162\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8B48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F81C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8348>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AE3AC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AE3388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AE3F48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AE3448>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AE3E48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AE3F48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 163\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056CAC848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05868AC88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05868AEC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056CACA48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05868AA88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7AE448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7AE508>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7AECC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7AE808>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7AE508>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 164\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↑0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053659508>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053659CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053659E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053659148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FD51C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053659C88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557B61C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059792688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB2F88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059792688>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 165\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.57 seconds,   \t7275 state expanded (0.18 unique) \t ~54.88 expansions/s\n",
      "Timestep: 166\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.48 seconds,   \t7306 state expanded (0.18 unique) \t ~56.43 expansions/s\n",
      "Timestep: 167\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t128.78 seconds,   \t7300 state expanded (0.17 unique) \t ~56.69 expansions/s\n",
      "Timestep: 168\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.16 seconds,   \t7326 state expanded (0.17 unique) \t ~56.29 expansions/s\n",
      "Timestep: 169\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.15 seconds,   \t7275 state expanded (0.18 unique) \t ~55.90 expansions/s\n",
      "Timestep: 170\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.39 seconds,   \t7306 state expanded (0.18 unique) \t ~56.03 expansions/s\n",
      "Timestep: 171\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A80DBC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A80D1C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A80D788>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A80DFC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533C5288>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFAE88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA5C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA6C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFAB88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA5C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 172\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EEDBC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EED808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EEDAC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EED748>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EED708>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA03C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0BC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0AC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0348>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0BC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 173\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057371C88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573712C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E93C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05459C0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B0E708>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B0EF48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B0E0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B0ED08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056979108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B0ED08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 174\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A03D48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A03BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A03288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A03E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B75108>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05326FE08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05326FC48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05326FC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05326FE88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05326FC08>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 175\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055100808>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05760FE88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055100FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054273148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05760F7C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05967D108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D26608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059056B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D26EC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059056B08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 176\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05459C348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0589F5448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0589F5D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0589F53C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0589F5DC8>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557D7448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DAD08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DA248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DA708>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DA248>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 177\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531CA548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A65388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05459C248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A65888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05402A448>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531CA948>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05402A108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05402A648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05402AC88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05402A648>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 178\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.24 seconds,   \t7365 state expanded (0.18 unique) \t ~56.12 expansions/s\n",
      "Timestep: 179\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.71 seconds,   \t7326 state expanded (0.17 unique) \t ~56.48 expansions/s\n",
      "Timestep: 180\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.56 seconds,   \t7275 state expanded (0.18 unique) \t ~55.72 expansions/s\n",
      "Timestep: 181\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.41 seconds,   \t7306 state expanded (0.18 unique) \t ~56.02 expansions/s\n",
      "Timestep: 182\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.65 seconds,   \t7300 state expanded (0.17 unique) \t ~56.30 expansions/s\n",
      "Timestep: 183\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.04 seconds,   \t7326 state expanded (0.17 unique) \t ~56.34 expansions/s\n",
      "Timestep: 184\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A792C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A79DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A798C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A79CC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A79EC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8848>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8A08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8AC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8848>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 185\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0D448>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E4CBC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E4C688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A13848>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056286AC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D46C88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D46588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D46448>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D46108>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D46588>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 186\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7DAC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053846188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7D388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DE90C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560A2F08>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7DC08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05524C708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05524C688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AD5248>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05524C688>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 187\n",
      "Joint action taken: ('→', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd→0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575F4E88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575F4688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575F44C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055551308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A4AEC8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E4CE48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E4C688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E4C248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055042048>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E4C248>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 188\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd→0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A24E08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A24808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05374A348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A13108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056296FC8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A24048>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A24B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053237A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05868DA48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053237A08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 189\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd←0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DD508>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DD2C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531DDAC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543F8308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581F6F88>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C51248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C51688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C51B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C51B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539BBC88>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 190\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd→0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554D5B88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A43108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A43AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A43488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545498C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A43248>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CC9688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A43D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CC9108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A43D48>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 191\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D →oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.41 seconds,   \t7253 state expanded (0.18 unique) \t ~56.05 expansions/s\n",
      "Timestep: 192\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↑0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.40 seconds,   \t7327 state expanded (0.17 unique) \t ~56.19 expansions/s\n",
      "Timestep: 193\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.64 seconds,   \t7300 state expanded (0.17 unique) \t ~55.88 expansions/s\n",
      "Timestep: 194\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.63 seconds,   \t7326 state expanded (0.17 unique) \t ~55.65 expansions/s\n",
      "Timestep: 195\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.33 seconds,   \t7275 state expanded (0.18 unique) \t ~55.39 expansions/s\n",
      "Timestep: 196\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D1A088>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1EE88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1E3C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1EDC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B1ED88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BCC108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BCC608>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BCCE08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BCCB08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BCC608>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 197\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812F48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0598123C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812888>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053452F88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A0CA88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A0C508>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A0C248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A0C808>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A0C508>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 198\n",
      "Joint action taken: ('↑', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CA0E48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053141C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531410C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053141F48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ED9608>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B32088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B32888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B32908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B32F88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B32888>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 199\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C04608>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA8348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C52788>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA8F48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA8B88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FD5848>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FD5948>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FD5E48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FD5908>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FD5948>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 200\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.60 seconds,   \t7327 state expanded (0.17 unique) \t ~56.10 expansions/s\n",
      "Timestep: 201\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.89 seconds,   \t7300 state expanded (0.17 unique) \t ~55.77 expansions/s\n",
      "Timestep: 202\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.65 seconds,   \t7326 state expanded (0.17 unique) \t ~56.51 expansions/s\n",
      "Timestep: 203\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.69 seconds,   \t7275 state expanded (0.18 unique) \t ~55.24 expansions/s\n",
      "Timestep: 204\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.80 seconds,   \t7306 state expanded (0.18 unique) \t ~55.86 expansions/s\n",
      "Timestep: 205\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.02 seconds,   \t7300 state expanded (0.17 unique) \t ~55.72 expansions/s\n",
      "Timestep: 206\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594E6888>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A28FAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594E6CC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A28F848>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594E6748>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594E6348>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD21C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD2F48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD2848>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058DD21C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 207\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B12648>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B12288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B12688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B12848>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B127C8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABC148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABCD48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABCA48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABCD88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABCD48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 208\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BFE088>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054739648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054739588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054739E88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9AAC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BA45C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BA4DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BA4908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BA4448>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BA4DC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 209\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572D3BC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058665988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058665388>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058665548>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A12208>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411C0C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B527C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B52D08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B52248>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B527C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 210\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B799888>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B799DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7999C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A12508>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A57908>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597A47C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0FC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B799308>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0B48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0FC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 211\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.78 seconds,   \t7317 state expanded (0.18 unique) \t ~55.95 expansions/s\n",
      "Timestep: 212\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.74 seconds,   \t7275 state expanded (0.18 unique) \t ~54.80 expansions/s\n",
      "Timestep: 213\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.90 seconds,   \t7306 state expanded (0.18 unique) \t ~55.81 expansions/s\n",
      "Timestep: 214\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.30 seconds,   \t7300 state expanded (0.17 unique) \t ~55.60 expansions/s\n",
      "Timestep: 215\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.51 seconds,   \t7326 state expanded (0.17 unique) \t ~56.57 expansions/s\n",
      "Timestep: 216\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.45 seconds,   \t7275 state expanded (0.18 unique) \t ~55.35 expansions/s\n",
      "Timestep: 217\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2A0F08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2A0908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2A0348>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2A05C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2A0748>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECF688>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECFFC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECF908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECF408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AECFFC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 218\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532CC248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532CCC48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532CCE88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532CCDC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF8588>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529DFE08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF8CC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF87C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF8A48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF8CC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 219\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EED188>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F1E4C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F1EBC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F1E808>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C6E348>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BAE208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BAEC88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BAEA88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BAE6C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BAEC88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 220\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730C48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05801EEC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0570AF348>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0570AF108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0570AF208>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0570AFB08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0570AF108>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 221\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BAD308>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BADB08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BAD988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BAD588>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BAD748>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531EB748>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531EBD08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531EBE08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531EBA08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531EBD08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 222\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADB01C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0592DC7C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0592DC148>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0592DCC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05930B608>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575C92C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F7B808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F7B188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F7B188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052BAD408>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 223\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B36208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580E5DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580E5648>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580E5F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560A5388>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054BAEAC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C39088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C39B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C39B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054BAE7C8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 224\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.01 seconds,   \t7327 state expanded (0.17 unique) \t ~56.36 expansions/s\n",
      "Timestep: 225\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.39 seconds,   \t7300 state expanded (0.17 unique) \t ~55.99 expansions/s\n",
      "Timestep: 226\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.05 seconds,   \t7326 state expanded (0.17 unique) \t ~56.33 expansions/s\n",
      "Timestep: 227\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A8C688>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E1FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E1188>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E1888>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537E1D08>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580DB088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580DBF08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580DB4C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580DB908>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580DBF08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 228\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05544D348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05544D488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05544D8C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05544DE08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05544DEC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596E7448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596E7FC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596E72C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596E7EC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596E7FC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 229\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433B508>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433B6C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433B1C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433B9C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05433BA48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DB988>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DB3C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DB608>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DB088>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0528DB3C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 230\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054860D48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594EE448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594EE0C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594EE888>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594EE988>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E46388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E46708>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E465C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E46288>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E46708>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 231\n",
      "Joint action taken: ('→', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059F46648>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055549108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055549348>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055549088>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055549DC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054807988>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2BE9C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A15348>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2BE208>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2BE9C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 232\n",
      "Joint action taken: ('←', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059048F08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053141748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053141808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531410C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05385FDC8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057D7D7C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053141688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A8C908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C425C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A8C908>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 233\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059E19CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059E19608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059E19C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053925B08>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E354C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058AAFF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AE2588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058AAFF48>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 234\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BC5D08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054487AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054487C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BC5548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0552558C8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580DB588>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554A1F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554A1D08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554A1CC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0554A1D08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 235\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd←0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053159948>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417DAC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05417D908>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597F7388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597F7988>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05496A248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057D7D148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05496AA88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05496AA88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0571CAC48>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 236\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd←0X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.83 seconds,   \t7266 state expanded (0.17 unique) \t ~55.96 expansions/s\n",
      "Timestep: 237\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.60 seconds,   \t7306 state expanded (0.18 unique) \t ~55.51 expansions/s\n",
      "Timestep: 238\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.10 seconds,   \t7300 state expanded (0.17 unique) \t ~56.11 expansions/s\n",
      "Timestep: 239\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.61 seconds,   \t7326 state expanded (0.17 unique) \t ~56.09 expansions/s\n",
      "Timestep: 240\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.06 seconds,   \t7275 state expanded (0.18 unique) \t ~55.51 expansions/s\n",
      "Timestep: 241\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.65 seconds,   \t7306 state expanded (0.18 unique) \t ~55.08 expansions/s\n",
      "Timestep: 242\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532F6D08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532F6508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532F6788>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BCE5248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BCE5D48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057781D08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057223C48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057223488>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057223C88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057223C48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 243\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A6C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369AF88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558780C8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053813A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DAB88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538134C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DA388>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DAB88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 244\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05586A908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B790108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280C908>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7909C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05280CAC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DA2448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A2DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A2948>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DA2D08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A2DC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 245\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B68848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056286548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052B68C08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0562869C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DC4788>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DC4A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DC4188>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DC4DC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A801DC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DC4188>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 246\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A2FC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A2E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A2048>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A2248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573A2108>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BCB8A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BCB8808>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BCB8988>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BCB84C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BCB8808>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 247\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.87 seconds,   \t7366 state expanded (0.18 unique) \t ~56.29 expansions/s\n",
      "Timestep: 248\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.94 seconds,   \t7326 state expanded (0.17 unique) \t ~56.38 expansions/s\n",
      "Timestep: 249\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.78 seconds,   \t7275 state expanded (0.18 unique) \t ~54.79 expansions/s\n",
      "Timestep: 250\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.03 seconds,   \t7306 state expanded (0.18 unique) \t ~55.34 expansions/s\n",
      "Timestep: 251\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.40 seconds,   \t7300 state expanded (0.17 unique) \t ~55.56 expansions/s\n",
      "Timestep: 252\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.81 seconds,   \t7326 state expanded (0.17 unique) \t ~56.44 expansions/s\n",
      "Timestep: 253\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055576408>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0555766C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055576108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055576208>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055576988>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547F89C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547F8CC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547F8EC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547F8F88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547F8CC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 254\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B78548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB4F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB41C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB49C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB4CC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3FA08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3F648>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3F588>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3F948>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3F648>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 255\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053776108>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B78DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053776F88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053909248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37D48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37408>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37E08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37808>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37988>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A37E08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 256\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C24A08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544FB908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A679B48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0544FBC08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9A988>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05284AA08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05284A748>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05284AEC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05284AE08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05284A748>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 257\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05966A408>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05966AFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05966ABC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05966A708>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C8AC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05561E348>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05561E5C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05561EEC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05561ED48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05561E5C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 258\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t133.52 seconds,   \t7275 state expanded (0.18 unique) \t ~54.48 expansions/s\n",
      "Timestep: 259\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.53 seconds,   \t7306 state expanded (0.18 unique) \t ~55.13 expansions/s\n",
      "Timestep: 260\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.32 seconds,   \t7300 state expanded (0.17 unique) \t ~56.02 expansions/s\n",
      "Timestep: 261\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.35 seconds,   \t7326 state expanded (0.17 unique) \t ~55.77 expansions/s\n",
      "Timestep: 262\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t131.32 seconds,   \t7275 state expanded (0.18 unique) \t ~55.40 expansions/s\n",
      "Timestep: 263\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t132.66 seconds,   \t7306 state expanded (0.18 unique) \t ~55.07 expansions/s\n",
      "Timestep: 264\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C4DC08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A673908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A673508>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A673588>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A673288>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056735C08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056735A08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056735D88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056735208>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056735A08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 265\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05362BE88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05939EF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BCB208>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05939EE88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A40948>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A673388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A6733C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A673908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05353E3C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A6733C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 266\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581710C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A545C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055690908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058171A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531B6B88>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A54808>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581AC988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581ACBC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581AC708>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581ACBC8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 267\n",
      "Joint action taken: ('stay', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CFAC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CF3C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CF408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CF388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05353E108>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543E7648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560D0408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055690808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E49088>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055690808>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 268\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd→0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C4DFC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534642C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05482D308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053464C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054071748>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05453A708>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05453A9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0574507C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560BC988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0574507C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 269\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059467A08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575D20C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575D27C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575D2848>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0575D2948>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CF2C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFAFC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFAF88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFAFC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 270\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560D0548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560D0B48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560D0348>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560D0E88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058755348>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05939E448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABDDC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABD348>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05939E408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABDDC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 271\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DD09C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597F7548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597F7CC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597F73C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573CF948>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613B4C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613BBC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613B488>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613BFC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05613BBC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 272\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t128.03 seconds,   \t7247 state expanded (0.18 unique) \t ~56.61 expansions/s\n",
      "Timestep: 273\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B77B48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B778C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B77D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B77F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B77888>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B77348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05595CE08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B77F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B77F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A57C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 274\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557E5188>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557E54C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BFA35C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054946D08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054946D48>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054946B88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054946F48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054946D88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DA2248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054946D88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 275\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C59348>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C59A88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C59948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C597C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536049C8>, (0, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53248>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057AF6148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057AF6048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53BC8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 276\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (1, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055690CC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055690108>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055690088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055690F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E91EC8>, (0, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D7C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D7C8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 277\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812C08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AB2248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AB2088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AB2BC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AB2E88>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059141988>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056203608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059141308>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059141308>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059141948>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 278\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054952808>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C8E488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054952D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053501188>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542B4DC8>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EE2C88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EE2F08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EE0648>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EE0648>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A15188>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 279\n",
      "Joint action taken: ('stay', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053755B88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0584A7488>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0584A7BC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594DB4C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594DB048>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053755988>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594DB348>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594DB488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058FF4488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594DB348>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 280\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D5C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D848>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D9C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477DD88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D788>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB7848>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CB18C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CB1A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CB1608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CB18C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 281\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053688108>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053688BC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053688148>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536886C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BFA35C8>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053688448>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675BDC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675B0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675B6C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675BDC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 282\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059389F08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053BD94C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053BD9C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053BD9648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C08348>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202B88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E52608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E52A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E52A48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E52FC8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 283\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), 'interact'), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05586A388>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05586A608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E0C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A23D08>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A23608>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A23F48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A23888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A23848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A23F48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 284\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E66388>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E66548>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E66B88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0555FE308>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E665C8>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05609A1C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05609A288>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05609A188>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056BDC888>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05609A188>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 285\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6F548>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6F448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6F848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6F708>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C6F5C8>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812148>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812788>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812348>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812348>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812D48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 286\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CD708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05609AAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05609AB48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE708>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05609A608>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541202C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054120408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8F08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054120408>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 287\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9B2C48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9B2748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542B4088>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05876AB88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05876A888>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05876A608>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EF7E48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EF7488>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EF7F88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EF7488>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 288\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533B40C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533B4088>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533B4DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054488848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054488F88>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058FF49C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058FF4488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058FF4088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058FF4088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058FF4F88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 289\n",
      "Joint action taken: ('→', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557E3788>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386D588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386DEC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05386DA88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0555FE908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202048>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202B08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202A88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054202048>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 290\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573C5548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053501408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053501688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597F7048>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E9AB48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557EB488>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557EB808>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557EB988>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557EBB48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557EB808>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 291\n",
      "Joint action taken: ('↑', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B32F88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B32388>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05477D1C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0048>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573C5AC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635E48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536350C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635E48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 292\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411CF08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054044688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D3E888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054044C88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055698148>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059389688>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054039488>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059389248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054039B08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054039488>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 293\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.56 seconds,   \t7403 state expanded (0.17 unique) \t ~57.14 expansions/s\n",
      "Timestep: 294\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.91 seconds,   \t7355 state expanded (0.17 unique) \t ~56.18 expansions/s\n",
      "Timestep: 295\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.96 seconds,   \t7266 state expanded (0.18 unique) \t ~55.91 expansions/s\n",
      "Timestep: 296\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.67 seconds,   \t7291 state expanded (0.18 unique) \t ~55.80 expansions/s\n",
      "Timestep: 297\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.30 seconds,   \t7275 state expanded (0.18 unique) \t ~55.83 expansions/s\n",
      "Timestep: 298\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.02 seconds,   \t7306 state expanded (0.18 unique) \t ~56.19 expansions/s\n",
      "Timestep: 299\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05385FB88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057093A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057093888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057093688>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057093C48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B95A508>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B95A308>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B95AF88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B95AA88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B95A308>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 300\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055878088>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056080C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055878EC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1948>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730388>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05385F9C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEA088>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEAB88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEAA08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DEA088>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 301\n",
      "Joint action taken: ('→', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F7B548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0556AE9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F7BEC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057437508>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054C53048>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE9B08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE9888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE9F08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE98C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE9888>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 302\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596DAF88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596DA7C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596DA288>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CD8108>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F7BA88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596DAFC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059C1C588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059C1C4C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059C1C5C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059C1C588>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 303\n",
      "Joint action taken: ('↓', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530ECEC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05586D2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05586D048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05586D808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530EC148>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FFC1C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B70AB88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056286708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FFCD08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056286708>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 304\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558C3588>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558C3E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558D1248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05393C348>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0596DA908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C0D2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C0D748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C0DC08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052C0D748>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 305\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFAA88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA9C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA5C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA288>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EFA148>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730588>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056169948>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058730088>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056169348>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056169948>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 306\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0594CE708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054843888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054843148>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054843408>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2B8A48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533E66C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533E6948>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533E6D48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533E6308>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533E6948>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 307\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B13C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0597B1F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B70AAC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B70A708>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053909848>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052847708>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05418C708>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05418CB08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05418CCC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05418C708>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 308\n",
      "Joint action taken: ('→', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.76 seconds,   \t7216 state expanded (0.18 unique) \t ~55.61 expansions/s\n",
      "Timestep: 309\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADB0208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADB0488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADB0648>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADB0E08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A4F688>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADB0BC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A4F988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A4F588>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F788C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A4F588>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 310\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059389388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059389708>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0593898C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05511C908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFC688>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933C708>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933CDC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933C488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933C488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F78188>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 311\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C24908>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C24D48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C24E88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C24C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C24188>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933C088>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933C788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933C288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933C288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05933C108>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 312\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FFD08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FF208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FFE48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C06EC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C06C88>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6C848>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6CA08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6C508>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6C248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6C508>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 313\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572B5E88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F88D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F88088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FF408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FFEC8>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055102C88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055102D88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0551022C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0551022C8>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055102BC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 314\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053395548>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B143C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B14608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B14C88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B142C8>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6CE48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6C7C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6C208>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6C208>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6C148>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 315\n",
      "Joint action taken: ('↓', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0584A6B88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FB8FC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0551021C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FB8C08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0532CC548>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0592EFA08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7AD1C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7ADAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7ADFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7AD1C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 316\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057230B08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DACC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DA648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567DADC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AEB3F48>, 'interact')]})), ((((0, -1), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA8208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05402E748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA8108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056DA8108>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F52308>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 317\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (1, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (((1, 0), (1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EB6C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EB248>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EB0C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058695988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537EBB88>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535A0EC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812348>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535A0B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F70188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059812348>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 318\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055EAA208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0584A66C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0584A6B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0584A6408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0584A6548>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5A048>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5AF08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5A0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5A0C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C5AB08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 319\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05506D6C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056184808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0561840C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0561845C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056184D88>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05379F388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05379F988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B74248>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A20388>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B74248>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 320\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F0D208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E6B2C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E6BF08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055627C88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055627388>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D21C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533ED6C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533ED588>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533ED708>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0533ED588>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 321\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A67CB48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A67CC08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A67C8C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A67CDC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F0DFC8>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8808>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED80C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EED808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EED808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EAE8C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 322\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056097548>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059048F08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059048148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059389AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538F0AC8>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0AF08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 323\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2788>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2748>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D21C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D2D08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A148>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4108>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EAE048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EAE888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EAE888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FF1988>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 324\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABC208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABC088>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABCC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ABC888>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4FC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4CC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558A4848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539104C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 325\n",
      "Joint action taken: ('↓', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547F3548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536CCD48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F9CE48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A4FE08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053635EC8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A4FBC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0536350C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547F30C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547F30C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 326\n",
      "Joint action taken: ('stay', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9EF208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EDC0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9EFF88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9EF7C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A17B48>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9EF6C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F0D908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9EFA48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F0DF88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9EFA48>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 327\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0592EFDC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0595F9DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558CE908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EE0188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537D1308>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057D82C08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057D82208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057D82188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E3BC48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057D82188>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 328\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd←0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A6B48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF4648>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054919B48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DF4C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8C6388>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0595F9688>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0595F9E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FFB08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581FFB08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053EAEB08>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 329\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd←0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C5CC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675BDC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675B408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675BA48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572E5508>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05675B888>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567CCD48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054638E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054638E48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05378CB08>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 330\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E3BD08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E3BAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E3B108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E3B648>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E3BA08>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531B67C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053395988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E3BF48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EEDAC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053395988>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 331\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.19 seconds,   \t7403 state expanded (0.17 unique) \t ~57.30 expansions/s\n",
      "Timestep: 332\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.54 seconds,   \t7355 state expanded (0.17 unique) \t ~56.34 expansions/s\n",
      "Timestep: 333\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.27 seconds,   \t7266 state expanded (0.18 unique) \t ~56.21 expansions/s\n",
      "Timestep: 334\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.74 seconds,   \t7291 state expanded (0.18 unique) \t ~55.77 expansions/s\n",
      "Timestep: 335\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.86 seconds,   \t7275 state expanded (0.18 unique) \t ~55.59 expansions/s\n",
      "Timestep: 336\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059044848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056238B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0562381C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056238448>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056238248>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545397C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054539DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545396C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054539988>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054539DC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 337\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A76F88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057255848>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A76D08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A76648>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059450908>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A711C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FE108>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FE208>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FED88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535FE108>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 338\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0573DCAC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054923408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054923208>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054923848>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0549235C8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B08948>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B08BC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8A08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AED8EC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B08BC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 339\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05868AE08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05868A788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0538478C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C8E248>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C8EB88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581A2F88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581A2208>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581A20C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581A2D08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0581A2208>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 340\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558AFE48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E0EE48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E0EA88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053E0E408>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054CB2B08>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572553C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057255388>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0572555C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057255D88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057255388>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 341\n",
      "Joint action taken: ('stay', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ED55C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ED5648>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ED5A08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A76748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ED5288>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F13908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F13EC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6CBC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052D6CBC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ED3308>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 342\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C8EA88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534D25C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C8E088>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558B1488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B341C8>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558B1F08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ED5188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ED5D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053ED5D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558B1288>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 343\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A5B388>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E3F208>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A5B488>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053395A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9EFB88>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531B6908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053755B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053755888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053755888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531B6E08>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 344\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t130.16 seconds,   \t7306 state expanded (0.18 unique) \t ~56.13 expansions/s\n",
      "Timestep: 345\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.64 seconds,   \t7300 state expanded (0.17 unique) \t ~56.31 expansions/s\n",
      "Timestep: 346\n",
      "Joint action taken: ('interact', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D →oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t129.13 seconds,   \t7326 state expanded (0.17 unique) \t ~56.73 expansions/s\n",
      "Timestep: 347\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054ECD148>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB05C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0FC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0C48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0808>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057EB0CC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8288>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8FC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8F88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8288>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 348\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05326F748>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B96AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B964C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B96A48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B96D88>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B96588>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B96288>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B96B48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B96D08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B96288>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 349\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A372C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822E808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822ED48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822EA08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822ECC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0591E7EC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0591E7488>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0591E7E08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0591E7DC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0591E7488>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 350\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A40E88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822E708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822EB48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822E288>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822E408>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB7E88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB7708>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB7748>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0529DD108>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB7708>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 351\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534625C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053462908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053462AC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053462C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053462088>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054919DC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B17F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B17808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B17388>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B17808>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 352\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053884F08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053884188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053884508>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053884048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BFFB48>, (1, 0))]})), ((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A40F88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE9248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE95C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE9808>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BE95C8>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 353\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C32908>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056259248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056259F08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056259C88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056259808>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056259DC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537836C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783988>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783648>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 354\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539C7088>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539C74C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539C7048>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539C7908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539C7888>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05326E248>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BDB3C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05326EFC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BDBEC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059BDB3C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 355\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7E3C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E656C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7EAC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E65788>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058B0D188>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A7E748>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5E88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5608>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5448>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540C5E88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 356\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t127.81 seconds,   \t7247 state expanded (0.18 unique) \t ~56.70 expansions/s\n",
      "Timestep: 357\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F1D308>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A5748>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A5208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A5DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A5248>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B090C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B09F48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B09DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B09DC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054B09648>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 358\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B19648>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B196C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B19D88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0579B0548>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057B199C8>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A82C088>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A82C048>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A82C7C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A82CF88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A82C7C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 359\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05567D7C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05567D708>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05567D0C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05567DC48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05567DBC8>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0561713C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056171188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056171308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056171308>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056171888>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 360\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057383988>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3F308>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3F148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3F188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C3F048>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530C03C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530C0D48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530C0248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530C0248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05873D208>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 361\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B9BF688>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A688>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369A248>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05369AB88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054952448>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054184488>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05738EFC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054184888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054184888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05738EF08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 362\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530E4748>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530E47C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0530E4C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05864D608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054952348>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054184D88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054184808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054184888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054184888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A535C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 363\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2A35C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A15C48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A15E48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A15888>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057C36FC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E7A88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E77C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E7F48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E7348>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0564E77C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 364\n",
      "Joint action taken: ('stay', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DA2CC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058735BC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DA2DC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0587353C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058BDF108>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052A61BC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540AC088>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540ACB88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540ACE48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540AC088>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 365\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O   Xd  X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BA7AC8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BA7D88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BA7B88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BA75C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055BA7CC8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535437C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053543FC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053543F88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053543608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053543FC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 366\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0547A5D08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0088>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C83748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054AA0208>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D8C488>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D8C708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A80D708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053D8C688>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A80D708>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 367\n",
      "Joint action taken: ('↓', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53748>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B602C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A53508>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B60448>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535BA688>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A274C88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A274848>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A274688>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A2743C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A274848>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 368\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↑0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058735308>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058735A08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411CD08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AC3108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B7AD848>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AC3C88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05607D388>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058735408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05873D4C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058735408>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 369\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↑0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05978CE08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05978C648>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05978CB88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05965D488>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05978C208>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CB11C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DA2108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D8E8C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056135D48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D8E8C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 370\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C02808>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05359D7C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05359DB48>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05359D788>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054A19C48>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C02648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EC6E88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EC6B88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EC6788>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054EC6E88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 371\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053B601C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB02C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05411CFC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB0B48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0571F86C8>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6B308>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6B1C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6B848>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6BE48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055E6B1C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 372\n",
      "Joint action taken: ('stay', '↑') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ↑oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Found goal after: \t127.95 seconds,   \t7243 state expanded (0.18 unique) \t ~56.61 expansions/s\n",
      "Timestep: 373\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FD3408>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05548E348>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05548ECC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054822608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054822E48>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05819A0C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05819AF08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05819A108>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05819AC08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05819A108>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 374\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0537834C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059CB1308>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADE7348>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05ADE7E08>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05626E588>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05626E2C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05626EB08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B723F08>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05626EB08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 375\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd→0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558DEF08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558DE608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558DE448>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557CD888>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557CDA88>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558DEE48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557CD248>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557CDE08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557CD408>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557CDE08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 376\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE5C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380A808>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380A908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380A508>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380A848>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F6E7C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F6E088>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F6E948>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F6E948>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054F6EE88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 377\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056810748>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FC7FC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FC71C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FC7A48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053FC7448>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B87FA08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FD36C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FD3588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FD3588>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FD3B08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 378\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd  X \n",
      "D   Xd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502F1C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05502F708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056246908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05819AA48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BED08>, 'interact')]})), ((((0, -1), (0, -1)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535F6588>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535F6A48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535F6788>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535F6788>, (0, -1)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0535F6F88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 379\n",
      "Joint action taken: ('←', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd  X \n",
      "D   Xd←0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, 1), 'interact'), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054574E08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05569CB88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054574408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0542A1408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F96F88>, (0, 0))]})), ((((0, -1), 'interact'), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A49548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783B88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783B88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053783C48>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 380\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd↑0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (1, 0))), (('interact', 'interact'),), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', 'interact'),), (('interact', (-1, 0)),), (('interact', 'interact'),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BEA08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560B6A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560B6688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560B63C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E21C8>, 'interact')]})), ((((0, -1), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D965C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A142C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A14208>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A14208>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056D96D08>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 381\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O ←oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, -1)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), 'interact'), ('interact', (-1, 0))), (('interact', 'interact'),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B87F148>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E20C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B87FA88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0AE08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A948>, (1, 0))]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05476B408>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0ABC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05864DD88>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05864DC48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05864DD88>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 382\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X →0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054574A08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056810408>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054574288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057194F88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558AC888>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E2748>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822ECC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E20C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531E20C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057704808>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 383\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0557B3108>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A17448>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A173C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057AF46C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053A17788>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05316A248>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057704048>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057704A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057704988>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057704048>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 384\n",
      "Joint action taken: ('←', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE648>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B718F08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B718588>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B718A88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B718B48>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8E68C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8E6DC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8E6A48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8E6E08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05B8E6DC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 385\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054172848>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054172F48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0541727C8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0545147C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054514D08>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A5C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A788>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A748>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056286B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058A0A788>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 386\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055509688>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056789608>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056789F48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567895C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056789148>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0567898C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DF7C48>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DF7B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DF7408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DF7C48>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 387\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E3EC48>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058E3EF48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F60148>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A80CA08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A80C148>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580EC4C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580EC7C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580EC6C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580ECA88>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0580EC6C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 388\n",
      "Joint action taken: ('←', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O ←oXd←0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ((1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), 'interact'), ('interact', (-1, 0))), (((0, -1), 'interact'), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact'))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', 'interact'),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A43B48>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A67CAC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A67C608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F9CC08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F9CD48>, 'interact')]})), ((((0, -1), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AFC288>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539CCCC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539CCB08>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539CCB08>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539CC4C8>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 389\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O ←oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (1, 0)), ((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (0, -1)), ((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), 'interact'), ('interact', (-1, 0))), (('interact', 'interact'),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380A548>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380AA88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0591DF188>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05380A248>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052997208>, (1, 0))]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052997648>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054509108>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054509188>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C3388>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054509188>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 390\n",
      "Joint action taken: ('←', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ←0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (-1, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05624E648>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05624E248>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05624EEC8>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05624E048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054099DC8>, (0, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053373208>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CA0948>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053373608>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0539CC588>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053CA0948>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 391\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558AC148>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558AC0C8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0558ACEC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8948>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052FC8048>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05385FB88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CFE48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CF048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0543CF048>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055A43E08>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 392\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O →oXd↓0X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', 'interact'),), (('interact', (0, 1)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), (1, 0)), ('interact', 'interact')), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (-1, 0))), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (1, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 3) facing (1, 0) holding dish@(1, 3)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (1, 0)), ('interact', (-1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055F96988>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05480F708>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055EAA2C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05480F988>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822EB88>, (-1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05822EA88>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A71FC8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A71A88>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A71508>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059A71A88>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 393\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05819ACC8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059064888>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E059064B08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057081908>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056286388>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05316AE08>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05316AEC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05316A888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05316A888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05316A688>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 394\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F8C688>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F8C648>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F8CCC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F8CE48>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053F8CDC8>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560B9E88>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560B97C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560B94C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0560B94C8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DF77C8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 395\n",
      "Joint action taken: ('stay', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X ↑0P \n",
      "O →oXd  X \n",
      "D   Xd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, 1), (0, 0)), ((-1, 0), (0, 0)), ('interact', (0, 0))), (((0, -1), 'interact'), ('interact', (-1, 0))), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (1, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 2) facing (1, 0) holding onion@(1, 2)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053DF7D08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B6B48>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B6148>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B6EC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0540B6748>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', (0, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ED4208>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ED4888>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ED4788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ED4788>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ED4AC8>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 396\n",
      "Joint action taken: ('↓', '↓') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd↓0X \n",
      "D ↓oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ((1, 0), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (((0, -1), (-1, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05505A408>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C1DC88>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BE688>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055C1D448>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0534C3AC8>, 'interact')]})), ((('interact', (-1, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0531BEA08>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E51D08>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E51288>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0591DF488>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054E51288>, (-1, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 397\n",
      "Joint action taken: ('←', '←') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd←0X \n",
      "D ←oXd  X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, 0)),), (('interact', (1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (0, 0))), (((0, -1), (0, -1)), ('interact', (0, 0))), (('interact', (0, 0)),), (((1, 0), (0, 0)), ('interact', (1, 0))), (((0, -1), (0, 0)), ('interact', (0, 0))), (((1, 0), (0, 0)), ('interact', 'interact')), (('interact', (-1, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((0, -1), (0, 0)), ('interact', 'interact')), (('interact', (1, 0)),), (((1, 0), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (1, 0) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 3), onion@(2, 1)], Order list: ['any']\n",
      "Successors for last node expanded:  [((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A141C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05455A6C8>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053825448>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056810EC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A14DC8>, (0, 0))]})), ((((0, -1), (0, 0)), ('interact', 'interact')), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DD0288>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DD0208>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DD0408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DD0408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052DD0D88>, 'interact')]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 398\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd↓0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056A149C8>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ECB408>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ECB588>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E057ECB908>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054822488>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055EAA108>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055EAA888>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055EAA448>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052F60CC8>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055EAA888>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 399\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [4:05:59<00:00, 14759.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path for last node expanded:  [None, (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (1, 0)),), (('interact', (0, 0)),), (((0, 1), (0, 0)), ((0, 1), (0, 0)), ((-1, 0), 'interact'), ('interact', (0, -1))), (((0, -1), (0, 0)), ((0, -1), (0, 0)), ('interact', (0, 0))), (('interact', (0, -1)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (('interact', (0, 0)),), (((1, 0), (1, 0)), ('interact', (0, 0))), (((0, -1), (0, 0)), ('interact', (0, 0)))]\n",
      "State of last node expanded:  Players: ((3, 1) facing (0, -1) holding dish@(3, 1), (1, 1) facing (1, 0) holding onion@(1, 1)), Objects: [soup@(3, 0) with state ('onion', 1, 0), dish@(2, 2)], Order list: ['any']\n",
      "Successors for last node expanded:  [((((1, 0), 'interact'), ('interact', (1, 0))), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E052E23248>, 2, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C7ACC8>, (0, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C7A388>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C7A888>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C7AB08>, (1, 0))]})), ((('interact', (0, 0)),), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056C7A2C8>, 1, defaultdict(<function ImitationAgentFromPolicy.reset.<locals>.<lambda> at 0x000001E055B4E708>, {1: [(<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B80548>, 'interact'), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B80648>, (-1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B80388>, (1, 0)), (<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E056B80548>, (0, 0))]}))]\n",
      "A* failed, taking random action\n",
      "Timestep: 400\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X X ø-X \n",
      "O   X   P \n",
      "O   Xd  X \n",
      "D ←oXd→0X \n",
      "X X X S X \n",
      "\n",
      "\n",
      "Avg reward 0.00 (std: 0.00, se: 0.00) over 1 games of avg length 400.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layouts = ['random0']\n",
    "horizon = {'random0': 1}\n",
    "omit_dict = {'P_BC_test+BC_test_1', 'P_BC_train+BC_test_1'}\n",
    "result = P_BC_evaluation(best_bc_model_paths, layouts, num_games=1, counter_dict=counters, omit_dict=omit_dict, delivery_horizons=horizon, \n",
    "                         set_history=True, seen_buffer=5, dist_heur=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random0': {'scores': {'P_BC_test+BC_test_0': (80.0, 0.0),\n",
       "   'P_BC_train+BC_test_0': (0.0, 0.0)},\n",
       "  'states': {'P_BC_test+BC_test_0': (3762.2675, 6411.4860123019635),\n",
       "   'P_BC_train+BC_test_0': (1977.59, 3108.514560348712)}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(result, \"data/planning/p_bc_evaluation_counter_random0.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random0': {'scores': {'P_BC_test+BC_test_0': (80.0, 0.0),\n",
       "   'P_BC_train+BC_test_0': (0.0, 0.0)},\n",
       "  'states': {'P_BC_test+BC_test_0': (3762.2675, 6411.4860123019635),\n",
       "   'P_BC_train+BC_test_0': (1977.59, 3108.514560348712)}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pickle(\"data/planning/p_bc_evaluation_counter_random0.pickle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-based planner + counters - simple (Too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delivery horizon for layout simple: 1\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "Mlp with different params or mdp found, computing from scratch\n",
      "Computing MediumLevelPlanner to be saved in c:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\data\\planners\\simple_am.pkl\n",
      "It took 0.34410667419433594 seconds to create mlp\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "Loaded MediumLevelPlanner from c:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\data\\planners\\simple_am.pkl\n",
      "Drop locations:  [(1, 0), (3, 0), (0, 2), (4, 2), (2, 3)]\n",
      "Pickup locations:  [(1, 0), (3, 0), (0, 2), (4, 2), (2, 3)]\n",
      "Valid counters:  [(1, 0), (3, 0), (0, 2), (4, 2), (2, 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X X P X X \n",
      "O     ↑1O \n",
      "X ↑0    X \n",
      "X D X S X \n",
      "\n",
      "Found goal after: \t1855.51 seconds,   \t8743 state expanded (0.37 unique) \t ~4.71 expansions/s\n",
      "Timestep: 1\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X P X X \n",
      "O ↑0  ↑1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1784.66 seconds,   \t8737 state expanded (0.37 unique) \t ~4.90 expansions/s\n",
      "Timestep: 2\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X P X X \n",
      "O ←0  ↑1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1847.06 seconds,   \t8741 state expanded (0.37 unique) \t ~4.73 expansions/s\n",
      "Timestep: 3\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X P X X \n",
      "O ←o  ↑1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1770.00 seconds,   \t8703 state expanded (0.37 unique) \t ~4.92 expansions/s\n",
      "Timestep: 4\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X P X X \n",
      "O   →o↑1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1766.51 seconds,   \t8703 state expanded (0.37 unique) \t ~4.93 expansions/s\n",
      "Timestep: 5\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X P X X \n",
      "O   ↑o→1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1762.01 seconds,   \t8703 state expanded (0.37 unique) \t ~4.94 expansions/s\n",
      "Timestep: 6\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X ø-X X \n",
      "O   ↑0→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1784.85 seconds,   \t8702 state expanded (0.37 unique) \t ~4.88 expansions/s\n",
      "Timestep: 7\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø-X X \n",
      "O ←0  →oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1462.50 seconds,   \t7337 state expanded (0.39 unique) \t ~5.02 expansions/s\n",
      "Timestep: 8\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X ø-X X \n",
      "O ←o←o  O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1354.71 seconds,   \t7072 state expanded (0.39 unique) \t ~5.22 expansions/s\n",
      "Timestep: 9\n",
      "Joint action taken: ('→', '↑') \t Reward: 0 + shape * 0 \n",
      "X X ø-X X \n",
      "O →o↑o  O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1351.72 seconds,   \t7072 state expanded (0.39 unique) \t ~5.23 expansions/s\n",
      "Timestep: 10\n",
      "Joint action taken: ('↓', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X ø=X X \n",
      "O   ↑1  O \n",
      "X ↓o    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1342.23 seconds,   \t7072 state expanded (0.39 unique) \t ~5.27 expansions/s\n",
      "Timestep: 11\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X X ø=X X \n",
      "O     →1O \n",
      "X   →o  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1351.05 seconds,   \t7072 state expanded (0.39 unique) \t ~5.23 expansions/s\n",
      "Timestep: 12\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø=X X \n",
      "O   ↑o→1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1361.87 seconds,   \t7072 state expanded (0.39 unique) \t ~5.19 expansions/s\n",
      "Timestep: 13\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø1X X \n",
      "O   ↑0→1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1384.81 seconds,   \t7071 state expanded (0.39 unique) \t ~5.11 expansions/s\n",
      "Timestep: 14\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø2X X \n",
      "O ←0  →1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1435.10 seconds,   \t8489 state expanded (0.37 unique) \t ~5.92 expansions/s\n",
      "Timestep: 15\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X ø3X X \n",
      "O ↑0  →1O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1105.79 seconds,   \t7834 state expanded (0.27 unique) \t ~7.08 expansions/s\n",
      "Timestep: 16\n",
      "Joint action taken: ('→', '↓') \t Reward: 0 + shape * 0 \n",
      "X X ø4X X \n",
      "O   →0  O \n",
      "X     ↓1X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t829.26 seconds,   \t5960 state expanded (0.28 unique) \t ~7.19 expansions/s\n",
      "Timestep: 17\n",
      "Joint action taken: ('→', '←') \t Reward: 0 + shape * 0 \n",
      "X X ø5X X \n",
      "O     →0O \n",
      "X   ←1  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t576.84 seconds,   \t4296 state expanded (0.28 unique) \t ~7.45 expansions/s\n",
      "Timestep: 18\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X X ø6X X \n",
      "O     →oO \n",
      "X ←1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t467.11 seconds,   \t3515 state expanded (0.30 unique) \t ~7.53 expansions/s\n",
      "Timestep: 19\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø7X X \n",
      "O   ←o  O \n",
      "X ←1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t254.41 seconds,   \t1842 state expanded (0.42 unique) \t ~7.24 expansions/s\n",
      "Timestep: 20\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X X ø8X X \n",
      "O ←o    O \n",
      "X ↓1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t186.19 seconds,   \t1342 state expanded (0.41 unique) \t ~7.21 expansions/s\n",
      "Timestep: 21\n",
      "Joint action taken: ('→', 'interact') \t Reward: 0 + shape * 0 \n",
      "X X ø9X X \n",
      "O   →o  O \n",
      "X ↓d    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t116.89 seconds,   \t794 state expanded (0.55 unique) \t ~6.79 expansions/s\n",
      "Timestep: 22\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø10X X \n",
      "O ←o    O \n",
      "X ↓d    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t80.84 seconds,   \t571 state expanded (0.48 unique) \t ~7.06 expansions/s\n",
      "Timestep: 23\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø11X X \n",
      "O ←o    O \n",
      "X ↓d    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t50.15 seconds,   \t343 state expanded (0.57 unique) \t ~6.84 expansions/s\n",
      "Timestep: 24\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X X ø12X X \n",
      "O ↑o    O \n",
      "X   →d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t28.67 seconds,   \t201 state expanded (0.72 unique) \t ~7.01 expansions/s\n",
      "Timestep: 25\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø13X X \n",
      "O ←o    O \n",
      "X   →d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t20.27 seconds,   \t136 state expanded (0.70 unique) \t ~6.71 expansions/s\n",
      "Timestep: 26\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø14X X \n",
      "O ←o    O \n",
      "X   →d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t13.16 seconds,   \t97 state expanded (0.75 unique) \t ~7.37 expansions/s\n",
      "Timestep: 27\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø15X X \n",
      "O ←o    O \n",
      "X   →d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t8.39 seconds,   \t60 state expanded (0.82 unique) \t ~7.15 expansions/s\n",
      "Timestep: 28\n",
      "Joint action taken: ('interact', '↑') \t Reward: 0 + shape * 0 \n",
      "X X ø16X X \n",
      "O ←o↑d  O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t5.26 seconds,   \t41 state expanded (0.85 unique) \t ~7.80 expansions/s\n",
      "Timestep: 29\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø17X X \n",
      "O ←o↑d  O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.45 seconds,   \t25 state expanded (0.84 unique) \t ~7.25 expansions/s\n",
      "Timestep: 30\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø18X X \n",
      "O ←o↑d  O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2.31 seconds,   \t13 state expanded (0.85 unique) \t ~5.64 expansions/s\n",
      "Timestep: 31\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X X ø19X X \n",
      "O   ↑d  O \n",
      "X ↓o    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.16 seconds,   \t14 state expanded (0.93 unique) \t ~12.08 expansions/s\n",
      "Timestep: 32\n",
      "Joint action taken: ('↑', '↑') \t Reward: 0 + shape * 0 \n",
      "X X ø20X X \n",
      "O ↑o↑d  O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.57 seconds,   \t7 state expanded (1.00 unique) \t ~12.18 expansions/s\n",
      "Timestep: 33\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O ↑0↑s  O \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.11 seconds,   \t4 state expanded (1.00 unique) \t ~37.27 expansions/s\n",
      "Timestep: 34\n",
      "Joint action taken: ('↑', '→') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O ↑0  →sO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.05 seconds,   \t3 state expanded (1.00 unique) \t ~55.23 expansions/s\n",
      "Timestep: 35\n",
      "Joint action taken: ('→', '↓') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O   →0  O \n",
      "X     ↓sX \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.01 seconds,   \t2 state expanded (1.00 unique) \t ~200.00 expansions/s\n",
      "Timestep: 36\n",
      "Joint action taken: ('←', 'interact') \t Reward: 20 + shape * 0 \n",
      "X XoP X X \n",
      "O ←0    O \n",
      "X     ↓1X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2726.40 seconds,   \t15966 state expanded (0.24 unique) \t ~5.86 expansions/s\n",
      "Timestep: 37\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O ←o    O \n",
      "X     ↓1X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2450.53 seconds,   \t13680 state expanded (0.23 unique) \t ~5.58 expansions/s\n",
      "Timestep: 38\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O   →o  O \n",
      "X     ↓1X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2414.87 seconds,   \t13680 state expanded (0.23 unique) \t ~5.66 expansions/s\n",
      "Timestep: 39\n",
      "Joint action taken: ('↑', '←') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O   ↑o  O \n",
      "X   ←1  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2334.50 seconds,   \t13680 state expanded (0.23 unique) \t ~5.86 expansions/s\n",
      "Timestep: 40\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø-X X \n",
      "O   ↑0  O \n",
      "X   ←1  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t2210.95 seconds,   \t13679 state expanded (0.23 unique) \t ~6.19 expansions/s\n",
      "Timestep: 41\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø-X X \n",
      "O     →0O \n",
      "X   ←1  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1745.03 seconds,   \t10082 state expanded (0.20 unique) \t ~5.78 expansions/s\n",
      "Timestep: 42\n",
      "Joint action taken: ('interact', '←') \t Reward: 0 + shape * 0 \n",
      "X Xoø-X X \n",
      "O     →oO \n",
      "X ←1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1320.12 seconds,   \t7873 state expanded (0.20 unique) \t ~5.96 expansions/s\n",
      "Timestep: 43\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø-X X \n",
      "O   ←o  O \n",
      "X ←1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1317.31 seconds,   \t7873 state expanded (0.20 unique) \t ~5.98 expansions/s\n",
      "Timestep: 44\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø-X X \n",
      "O   ↑o  O \n",
      "X ←1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1314.70 seconds,   \t7873 state expanded (0.20 unique) \t ~5.99 expansions/s\n",
      "Timestep: 45\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø=X X \n",
      "O   ↑0  O \n",
      "X ←1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1329.47 seconds,   \t7872 state expanded (0.20 unique) \t ~5.92 expansions/s\n",
      "Timestep: 46\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X Xoø=X X \n",
      "O ←0    O \n",
      "X ↓1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1485.55 seconds,   \t7706 state expanded (0.25 unique) \t ~5.19 expansions/s\n",
      "Timestep: 47\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø=X X \n",
      "O ←o    O \n",
      "X ↓1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1021.18 seconds,   \t5866 state expanded (0.25 unique) \t ~5.74 expansions/s\n",
      "Timestep: 48\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø=X X \n",
      "O   →o  O \n",
      "X ↓1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1015.25 seconds,   \t5866 state expanded (0.25 unique) \t ~5.78 expansions/s\n",
      "Timestep: 49\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø=X X \n",
      "O   ↑o  O \n",
      "X ↓1    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1011.05 seconds,   \t5866 state expanded (0.25 unique) \t ~5.80 expansions/s\n",
      "Timestep: 50\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X Xoø1X X \n",
      "O   ↑0  O \n",
      "X ↓d    X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1013.09 seconds,   \t5865 state expanded (0.25 unique) \t ~5.79 expansions/s\n",
      "Timestep: 51\n",
      "Joint action taken: ('→', '→') \t Reward: 0 + shape * 0 \n",
      "X Xoø2X X \n",
      "O     →0O \n",
      "X   →d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t880.90 seconds,   \t5086 state expanded (0.27 unique) \t ~5.77 expansions/s\n",
      "Timestep: 52\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø3X X \n",
      "O     →oO \n",
      "X   →d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t719.33 seconds,   \t4153 state expanded (0.30 unique) \t ~5.77 expansions/s\n",
      "Timestep: 53\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø4X X \n",
      "O     →oO \n",
      "X   →d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t514.65 seconds,   \t3132 state expanded (0.33 unique) \t ~6.09 expansions/s\n",
      "Timestep: 54\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø5X X \n",
      "O     →oO \n",
      "X   →d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t351.48 seconds,   \t2308 state expanded (0.36 unique) \t ~6.57 expansions/s\n",
      "Timestep: 55\n",
      "Joint action taken: ('interact', '↑') \t Reward: 0 + shape * 0 \n",
      "X Xoø6X X \n",
      "O   ↑d→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t248.97 seconds,   \t1660 state expanded (0.39 unique) \t ~6.67 expansions/s\n",
      "Timestep: 56\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø7X X \n",
      "O   ↑d→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t174.42 seconds,   \t1154 state expanded (0.43 unique) \t ~6.62 expansions/s\n",
      "Timestep: 57\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø8X X \n",
      "O   ↑d→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t117.99 seconds,   \t825 state expanded (0.41 unique) \t ~6.99 expansions/s\n",
      "Timestep: 58\n",
      "Joint action taken: ('↑', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø9X X \n",
      "O   ↑d↑oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t70.91 seconds,   \t515 state expanded (0.52 unique) \t ~7.26 expansions/s\n",
      "Timestep: 59\n",
      "Joint action taken: ('→', '↑') \t Reward: 0 + shape * 0 \n",
      "X Xoø10X X \n",
      "O   ↑d→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t53.46 seconds,   \t380 state expanded (0.56 unique) \t ~7.11 expansions/s\n",
      "Timestep: 60\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X Xoø11X X \n",
      "O   ↑d→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t33.29 seconds,   \t260 state expanded (0.58 unique) \t ~7.81 expansions/s\n",
      "Timestep: 61\n",
      "Joint action taken: ('interact', '↓') \t Reward: 0 + shape * 0 \n",
      "X Xoø12X X \n",
      "O     →oO \n",
      "X   ↓d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t20.74 seconds,   \t171 state expanded (0.68 unique) \t ~8.24 expansions/s\n",
      "Timestep: 62\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø13X X \n",
      "O     →oO \n",
      "X   ↓d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t11.96 seconds,   \t110 state expanded (0.75 unique) \t ~9.20 expansions/s\n",
      "Timestep: 63\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø14X X \n",
      "O     →oO \n",
      "X   ↓d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t7.63 seconds,   \t83 state expanded (0.78 unique) \t ~10.88 expansions/s\n",
      "Timestep: 64\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø15X X \n",
      "O     →oO \n",
      "X   ↓d  X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t4.85 seconds,   \t51 state expanded (0.84 unique) \t ~10.52 expansions/s\n",
      "Timestep: 65\n",
      "Joint action taken: ('interact', '↑') \t Reward: 0 + shape * 0 \n",
      "X Xoø16X X \n",
      "O   ↑d→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t3.17 seconds,   \t37 state expanded (0.84 unique) \t ~11.68 expansions/s\n",
      "Timestep: 66\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø17X X \n",
      "O   ↑d→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.86 seconds,   \t20 state expanded (0.90 unique) \t ~10.77 expansions/s\n",
      "Timestep: 67\n",
      "Joint action taken: ('interact', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø18X X \n",
      "O   ↑d→oO \n",
      "X       X \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t1.03 seconds,   \t11 state expanded (0.82 unique) \t ~10.64 expansions/s\n",
      "Timestep: 68\n",
      "Joint action taken: ('↓', 'stay') \t Reward: 0 + shape * 0 \n",
      "X Xoø19X X \n",
      "O   ↑d  O \n",
      "X     ↓oX \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.50 seconds,   \t10 state expanded (1.00 unique) \t ~20.06 expansions/s\n",
      "Timestep: 69\n",
      "Joint action taken: ('→', '↑') \t Reward: 0 + shape * 0 \n",
      "X Xoø20X X \n",
      "O   ↑d  O \n",
      "X     →oX \n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.47 seconds,   \t7 state expanded (1.00 unique) \t ~14.80 expansions/s\n",
      "Timestep: 70\n",
      "Joint action taken: ('interact', 'interact') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O   ↑s  O \n",
      "X     →0Xo\n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.09 seconds,   \t2 state expanded (1.00 unique) \t ~21.58 expansions/s\n",
      "Timestep: 71\n",
      "Joint action taken: ('↓', '→') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O     →sO \n",
      "X     ↓0Xo\n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.02 seconds,   \t2 state expanded (1.00 unique) \t ~106.16 expansions/s\n",
      "Timestep: 72\n",
      "Joint action taken: ('←', '↓') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O       O \n",
      "X   ←0↓sXo\n",
      "X D X S X \n",
      "\n",
      "\n",
      "Found goal after: \t0.01 seconds,   \t2 state expanded (1.00 unique) \t ~200.00 expansions/s\n",
      "Timestep: 73\n",
      "Joint action taken: ('↑', 'interact') \t Reward: 20 + shape * 0 \n",
      "X XoP X X \n",
      "O   ↑0  O \n",
      "X     ↓1Xo\n",
      "X D X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, ((-1, 0), (0, 0)), ((0, 1), (0, 1)), ((-1, 0), (0, 0)), ((1, 0), (0, 0))]\n",
      "State of last node expanded:  Players: ((3, 2) facing (1, 0) holding onion@(3, 2), (1, 2) facing (0, 1) holding None), Objects: [onion@(1, 0), onion@(4, 2), soup@(2, 0) with state ('onion', 3, 20), onion@(3, 0), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [(((0, -1), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05464D4C8>, 1), (((0, 1), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A48E508>, 1), (((1, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A08D448>, 1), (((-1, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E065C4F288>, 1), (((0, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A359C08>, 1), (('interact', (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05A1C1808>, 1)]\n",
      "A* failed, taking random action\n",
      "Timestep: 74\n",
      "Joint action taken: ('stay', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O   ↑0  O \n",
      "X     ↓1Xo\n",
      "X D X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, ((-1, 0), (0, 0)), ((0, 1), (0, 1)), ((-1, 0), (0, 0)), ((1, 0), (0, 0))]\n",
      "State of last node expanded:  Players: ((3, 2) facing (1, 0) holding onion@(3, 2), (1, 2) facing (0, 1) holding None), Objects: [onion@(1, 0), onion@(4, 2), soup@(2, 0) with state ('onion', 3, 20), onion@(3, 0), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [(((0, -1), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058ADDE88>, 1), (((0, 1), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058449E08>, 1), (((1, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0586B9548>, 1), (((-1, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0586B95C8>, 1), (((0, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E058ACD208>, 1), (('interact', (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E0666F5848>, 1)]\n",
      "A* failed, taking random action\n",
      "Timestep: 75\n",
      "Joint action taken: ('→', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O     →0O \n",
      "X     ↓1Xo\n",
      "X D X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, ((-1, 0), (0, 0)), ((0, 1), (0, 1)), ((-1, 0), (0, 0)), ((1, 0), (0, 0))]\n",
      "State of last node expanded:  Players: ((3, 2) facing (1, 0) holding onion@(3, 2), (1, 2) facing (0, 1) holding None), Objects: [onion@(1, 0), onion@(4, 2), soup@(2, 0) with state ('onion', 3, 20), onion@(3, 0), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [(((0, -1), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E055AD65C8>, 1), (((0, 1), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E065EE9688>, 1), (((1, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05BF86208>, 1), (((-1, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05870E7C8>, 1), (((0, 0), (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05870E5C8>, 1), (('interact', (0, 0)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05870E888>, 1)]\n",
      "A* failed, taking random action\n",
      "Timestep: 76\n",
      "Joint action taken: ('↓', '←') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O       O \n",
      "X   ←1↓0Xo\n",
      "X D X S X \n",
      "\n",
      "\n",
      "Path for last node expanded:  [None, ((0, 1), (0, 1)), ((1, 0), (-1, 0)), ((0, 0), (0, 0)), ((0, -1), (0, 0)), ((0, 1), (0, 0))]\n",
      "State of last node expanded:  Players: ((3, 2) facing (0, 1) holding onion@(3, 2), (1, 2) facing (-1, 0) holding None), Objects: [onion@(1, 0), onion@(4, 2), soup@(2, 0) with state ('onion', 3, 20), onion@(3, 0), onion@(2, 3)], Order list: ['any']\n",
      "Successors for last node expanded:  [(((0, -1), (0, -1)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E04B1A98C8>, 1), (((0, 1), (0, -1)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05AA14E48>, 1), (((1, 0), (0, -1)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E054331148>, 1), (((-1, 0), (0, -1)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AE0CC8>, 1), (((0, 0), (0, -1)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E053AE0F08>, 1), (('interact', (0, -1)), <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x000001E05986BD48>, 1)]\n",
      "A* failed, taking random action\n",
      "Timestep: 77\n",
      "Joint action taken: ('←', 'stay') \t Reward: 0 + shape * 0 \n",
      "X XoP X X \n",
      "O       O \n",
      "X   ←1←0Xo\n",
      "X D X S X \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [16:21:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15484\\158592662.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0momit_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m result = P_BC_evaluation(best_bc_model_paths, layouts, num_games=1, counter_dict=counters, omit_dict=omit_dict, delivery_horizons=horizon, \n\u001b[1;32m----> 5\u001b[1;33m                          set_history=True, seen_buffer=5, dist_heur=True)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\human_aware_rl\\experiments\\planning_experiments.py\u001b[0m in \u001b[0;36mP_BC_evaluation\u001b[1;34m(best_bc_models, layouts, num_games, horizon, counter_dict, omit_dict, delivery_horizons, set_history, seen_buffer, return_best, bc_stochastic, dist_heur)\u001b[0m\n\u001b[0;32m    124\u001b[0m                                                              \u001b[0mbest_bc_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_games\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_games\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelivery_horizons\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelivery_horizons\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                                                              \u001b[0momit_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0momit_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseen_buffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseen_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                                                              return_best=return_best, bc_stochastic=bc_stochastic, dist_heur=dist_heur)\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp_bc_evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\human_aware_rl\\experiments\\planning_experiments.py\u001b[0m in \u001b[0;36mP_BC_evaluation_for_layout\u001b[1;34m(ae, layout, best_bc_models, num_games, delivery_horizons, omit_dict, set_history, seen_buffer, return_best, bc_stochastic, dist_heur)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp_bc_test_bc_name\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0momit_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0map_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgentPair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_bc_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_bc_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mdata0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_agent_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_games\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_games\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mlayout_p_bc_eval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"scores\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_bc_test_bc_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_and_std_err\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ep_returns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mlayout_p_bc_eval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"states\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_bc_test_bc_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_and_std_err\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ep_states'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\agents\\benchmarking.py\u001b[0m in \u001b[0;36mevaluate_agent_pair\u001b[1;34m(self, agent_pair, num_games, display, info)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_agent_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_pair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_games\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_rollouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_pair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_games\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\mdp\\overcooked_env.py\u001b[0m in \u001b[0;36mget_rollouts\u001b[1;34m(self, agent_pair, num_games, display, final_state, agent_idx, reward_shaping, display_until, info)\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0magent_pair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_mdp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mtrajectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtot_rews_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtot_rews_shaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_agents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_pair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_final_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_until\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplay_until\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates_expl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[0mtrajectories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ep_observations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\mdp\\overcooked_env.py\u001b[0m in \u001b[0;36mrun_agents\u001b[1;34m(self, agent_pair, include_final_state, display, display_until)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0ms_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mjoi_a_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoi_a_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates_expl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent_pair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoint_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m             \u001b[0ma_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjoi_a_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoi_a_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\agents\\agent.py\u001b[0m in \u001b[0;36mjoint_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maction_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstates_expl_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates_expl_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoint_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\agents\\agent.py\u001b[0m in \u001b[0;36mjoint_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates_expl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates_expl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\agents\\agent.py\u001b[0m in \u001b[0;36maction\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         search_problem = SearchTree(start_state, goal_fn, expand_fn, heuristic_fn, max_seen_count=self.seen_buffer, max_iter_count=50000, \n\u001b[1;32m--> 265\u001b[1;33m                                     return_best=self.return_best, history=self.history)\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\planning\\search.py\u001b[0m in \u001b[0;36mA_star_graph_search\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcurr_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0msuccessors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurr_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0msuccessors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\agents\\agent.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(state, history)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mother_agent_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0minitial_env_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mother_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         expand_fn = lambda state, history=None: self.mlp.get_successor_states_fixed_other(state, self.other_agent, other_agent_index, \n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\planning\\planners.py\u001b[0m in \u001b[0;36mget_successor_states_fixed_other\u001b[1;34m(self, start_state, other_agent, other_agent_idx, history, set_history)\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mml_action\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mml_actions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mset_history\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                 \u001b[0maction_plan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_embedded_low_level_action_plan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_agent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_agent_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1090\u001b[0m                 \u001b[0mother_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_hist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\planning\\planners.py\u001b[0m in \u001b[0;36mget_embedded_low_level_action_plan\u001b[1;34m(self, state, goal_pos_and_or, other_agent, other_agent_idx, history)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m         \u001b[0msearch_problem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSearchTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoal_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheuristic_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mstate_action_plan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_problem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA_star_graph_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[0maction_plan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_plan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstate_action_plan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[0maction_plan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_plan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\planning\\search.py\u001b[0m in \u001b[0;36mA_star_graph_search\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcurr_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0msuccessors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurr_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0msuccessors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\planning\\planners.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(state, hist)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[0magent_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mother_agent_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m         \u001b[0mexpand_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedded_mdp_succ_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_agent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m         \u001b[0mgoal_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0magent_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_and_or\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgoal_pos_and_or\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_orders_remaining\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0mheuristic_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0magent_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoal_pos_and_or\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\overcooked_ai\\overcooked_ai_py\\planning\\planners.py\u001b[0m in \u001b[0;36membedded_mdp_succ_fn\u001b[1;34m(self, state, other_agent, history)\u001b[0m\n\u001b[0;32m   1127\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[0mother_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m         \u001b[0mother_agent_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0msuccessors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\human_aware_rl\\imitation\\behavioural_cloning.py\u001b[0m in \u001b[0;36maction\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\human_aware_rl\\imitation\\behavioural_cloning.py\u001b[0m in \u001b[0;36mactions\u001b[1;34m(self, states, agent_indices)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mall_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_indices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\human_aware_rl\\imitation\\behavioural_cloning.py\u001b[0m in \u001b[0;36mmulti_action\u001b[1;34m(self, states, agent_indices)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmulti_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0maction_probs_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_waits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Need to set the agent_index or mdp of the Agent before using it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\human_aware_rl\\imitation\\behavioural_cloning.py\u001b[0m in \u001b[0;36mstate_policy\u001b[1;34m(mdp_states, agent_indices, include_waits, stochastic)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0maction_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded_state_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_waits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction_probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\human_aware_rl\\imitation\\behavioural_cloning.py\u001b[0m in \u001b[0;36mencoded_state_policy\u001b[1;34m(observations, include_waits, stochastic)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencoded_state_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_waits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0maction_probs_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_waits\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\stable-baselines\\stable_baselines\\common\\base_class.py\u001b[0m in \u001b[0;36maction_probability\u001b[1;34m(self, observation, state, mask, actions)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[0mactions_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproba_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions_proba\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# empty list means not implemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jhjhe\\documents\\delft\\rp\\human_aware_rl\\stable-baselines\\stable_baselines\\common\\policies.py\u001b[0m in \u001b[0;36mproba_step\u001b[1;34m(self, obs, state, mask)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mproba_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy_proba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_ph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jhjhe\\anaconda3\\envs\\overcooked_ai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layouts = ['simple']\n",
    "horizon = {'simple': 1}\n",
    "omit_dict = {}\n",
    "result = P_BC_evaluation(best_bc_model_paths, layouts, num_games=1, counter_dict=counters, omit_dict=omit_dict, delivery_horizons=horizon, \n",
    "                         set_history=True, seen_buffer=5, dist_heur=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "overcooked_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
